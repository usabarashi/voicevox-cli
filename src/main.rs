use anyhow::{anyhow, Result};
use clap::{Arg, Command};
use rodio::{Decoder, OutputStream, Sink};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::ffi::{CStr, CString};
use std::fs;
use std::io::Cursor;
use std::path::PathBuf;
use std::ptr;

// Use bindgen-generated bindings if available
#[cfg(feature = "use_bindgen")]
include!(concat!(env!("OUT_DIR"), "/bindings.rs"));

// Define constants for result codes (bindgen may not expose them properly)
#[cfg(feature = "use_bindgen")]
pub const VOICEVOX_RESULT_OK: i32 = 0;

// If bindgen fails, provide manual bindings (simplified)
#[cfg(not(feature = "use_bindgen"))]
mod manual_bindings {
    use libc::{c_char, c_int, c_uchar, c_uint, uintptr_t};

    pub const VOICEVOX_RESULT_OK: c_int = 0;
    pub type VoicevoxStyleId = c_uint;

    // Acceleration mode enum for macOS CPU-only processing
    #[repr(C)]
    #[derive(Clone, Copy)]
    pub enum VoicevoxAccelerationMode {
        Auto = 0,
        Cpu = 1,
        Gpu = 2,
    }

    // Initialize options structure for CPU-only mode
    #[repr(C)]
    #[derive(Clone, Copy)]
    pub struct VoicevoxInitializeOptions {
        pub acceleration_mode: VoicevoxAccelerationMode,
        pub cpu_num_threads: u16,
    }

    // Opaque types
    pub enum VoicevoxSynthesizer {}
    pub enum VoicevoxOnnxruntime {}
    pub enum OpenJtalkRc {}
    pub enum VoicevoxLoadOnnxruntimeOptions {}
    pub enum VoicevoxTtsOptions {}
    pub enum VoicevoxSynthesisOptions {}
    pub enum VoicevoxVoiceModelFile {}

    extern "C" {
        // Core initialization functions
        pub fn voicevox_make_default_load_onnxruntime_options(
        ) -> *const VoicevoxLoadOnnxruntimeOptions;
        pub fn voicevox_onnxruntime_load_once(
            options: *const VoicevoxLoadOnnxruntimeOptions,
            onnxruntime: *mut *const VoicevoxOnnxruntime,
        ) -> c_int;

        pub fn voicevox_open_jtalk_rc_new(
            open_jtalk_dic_dir: *const c_char,
            open_jtalk_rc: *mut *mut OpenJtalkRc,
        ) -> c_int;

        // Initialize options with CPU-only mode
        pub fn voicevox_synthesizer_new(
            onnxruntime: *const VoicevoxOnnxruntime,
            open_jtalk_rc: *mut OpenJtalkRc,
            options: VoicevoxInitializeOptions,
            synthesizer: *mut *mut VoicevoxSynthesizer,
        ) -> c_int;

        // TTS functions
        pub fn voicevox_make_default_tts_options() -> *const VoicevoxTtsOptions;
        pub fn voicevox_synthesizer_tts(
            synthesizer: *mut VoicevoxSynthesizer,
            text: *const c_char,
            style_id: VoicevoxStyleId,
            options: *const VoicevoxTtsOptions,
            wav_length: *mut uintptr_t,
            wav: *mut *mut c_uchar,
        ) -> c_int;

        // Metadata functions
        pub fn voicevox_synthesizer_create_metas_json(
            synthesizer: *mut VoicevoxSynthesizer,
        ) -> *mut c_char;

        // Model loading functions
        pub fn voicevox_synthesizer_load_voice_model(
            synthesizer: *const VoicevoxSynthesizer,
            model: *const VoicevoxVoiceModelFile,
        ) -> c_int;

        pub fn voicevox_voice_model_file_open(
            path: *const c_char,
            model: *mut *mut VoicevoxVoiceModelFile,
        ) -> c_int;

        pub fn voicevox_voice_model_file_delete(model: *mut VoicevoxVoiceModelFile);

        // Cleanup functions
        pub fn voicevox_wav_free(wav: *mut c_uchar);
        pub fn voicevox_json_free(json: *mut c_char);
        pub fn voicevox_synthesizer_delete(synthesizer: *mut VoicevoxSynthesizer);
        pub fn voicevox_open_jtalk_rc_delete(open_jtalk_rc: *mut OpenJtalkRc);
    }
}

#[cfg(not(feature = "use_bindgen"))]
use manual_bindings::*;

#[derive(Debug, Serialize, Deserialize)]
struct Speaker {
    name: String,
    #[serde(default)]
    speaker_uuid: String,
    styles: Vec<Style>,
    #[serde(default)]
    version: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct Style {
    name: String,
    id: u32,
    #[serde(rename = "type", skip_serializing_if = "Option::is_none")]
    style_type: Option<String>,
}

#[derive(Debug)]
struct VoicevoxCore {
    synthesizer: *mut VoicevoxSynthesizer,
    _open_jtalk_rc: *mut OpenJtalkRc,
}

unsafe impl Send for VoicevoxCore {}
unsafe impl Sync for VoicevoxCore {}

impl VoicevoxCore {
    fn new() -> Result<Self> {
        unsafe {
            // Load ONNX Runtime first
            let load_options = voicevox_make_default_load_onnxruntime_options();
            let mut onnxruntime: *const VoicevoxOnnxruntime = ptr::null();

            let result = voicevox_onnxruntime_load_once(load_options, &mut onnxruntime);
            if result != VOICEVOX_RESULT_OK {
                return Err(anyhow!(
                    "ONNX Runtime initialization failed: code {}",
                    result
                ));
            }

            // Initialize OpenJTalk
            let dict_path = find_openjtalk_dict()?;
            let dict_cstr = CString::new(dict_path)?;
            let mut open_jtalk_rc: *mut OpenJtalkRc = ptr::null_mut();

            let result = voicevox_open_jtalk_rc_new(dict_cstr.as_ptr(), &mut open_jtalk_rc);
            if result != VOICEVOX_RESULT_OK {
                return Err(anyhow!(
                    "OpenJTalk RC initialization failed: code {}",
                    result
                ));
            }

            // Create synthesizer with CPU-only mode for macOS
            #[cfg(target_os = "macos")]
            {
                println!("üñ•Ô∏è  Initializing VOICEVOX Core in CPU-only mode for macOS...");

                // Create CPU-only initialization options structure
                let init_options = VoicevoxInitializeOptions {
                    acceleration_mode: VoicevoxAccelerationMode::Cpu, // Force CPU mode, no GPU testing
                    cpu_num_threads: 0, // Use default number of CPU threads (0 = auto-detect)
                };

                let mut synthesizer: *mut VoicevoxSynthesizer = ptr::null_mut();
                let result = voicevox_synthesizer_new(
                    onnxruntime,
                    open_jtalk_rc,
                    init_options,
                    &mut synthesizer,
                );

                if result != VOICEVOX_RESULT_OK {
                    voicevox_open_jtalk_rc_delete(open_jtalk_rc);
                    return Err(anyhow!("Synthesizer creation failed: code {}", result));
                }

                println!("‚úÖ Initialization completed successfully");

                // Skip loading any default models - load only what's needed later
                // This makes startup much faster!

                Ok(VoicevoxCore {
                    synthesizer,
                    _open_jtalk_rc: open_jtalk_rc,
                })
            }

            // Fallback for non-macOS platforms - also use CPU-only mode
            #[cfg(not(target_os = "macos"))]
            {
                println!("üñ•Ô∏è  Initializing VOICEVOX Core in CPU-only mode...");

                // Create CPU-only initialization options structure
                let init_options = VoicevoxInitializeOptions {
                    acceleration_mode: VoicevoxAccelerationMode::Cpu, // Force CPU mode, no GPU testing
                    cpu_num_threads: 0, // Use default number of CPU threads (0 = auto-detect)
                };

                let mut synthesizer: *mut VoicevoxSynthesizer = ptr::null_mut();
                let result = voicevox_synthesizer_new(
                    onnxruntime,
                    open_jtalk_rc,
                    init_options,
                    &mut synthesizer,
                );

                if result != VOICEVOX_RESULT_OK {
                    voicevox_open_jtalk_rc_delete(open_jtalk_rc);
                    return Err(anyhow!("Synthesizer creation failed: code {}", result));
                }

                println!("‚úÖ Initialization completed successfully");

                // Do not load any models by default for fastest startup
                // Models will be loaded on demand based on the requested voice
                println!("üöÄ Core initialized - models will be loaded on demand");

                Ok(VoicevoxCore {
                    synthesizer,
                    _open_jtalk_rc: open_jtalk_rc,
                })
            }
        }
    }

    // Helper function to get the model number for a given voice/style ID

    fn load_default_models(synthesizer: *mut VoicevoxSynthesizer) -> Result<()> {
        // Load only essential models for faster startup
        // Priority: „Åö„Çì„Å†„ÇÇ„Çì (3.vvm), ÂõõÂõΩ„ÇÅ„Åü„Çì (2.vvm), Êò•Êó•ÈÉ®„Å§„ÇÄ„Åé (8.vvm)
        let default_models = ["3.vvm", "2.vvm", "8.vvm"];

        let models_dir = find_models_dir()?;

        println!("üì¶ Loading default VVM models for faster startup...");

        let mut loaded_count = 0;
        for model_name in &default_models {
            let model_path = models_dir.join(model_name);
            if model_path.exists() {
                if let Some(path_str) = model_path.to_str() {
                    if let Ok(path_cstr) = CString::new(path_str) {
                        unsafe {
                            let mut model: *mut VoicevoxVoiceModelFile = ptr::null_mut();
                            let result =
                                voicevox_voice_model_file_open(path_cstr.as_ptr(), &mut model);
                            if result == VOICEVOX_RESULT_OK {
                                let load_result =
                                    voicevox_synthesizer_load_voice_model(synthesizer, model);
                                if load_result == VOICEVOX_RESULT_OK {
                                    loaded_count += 1;
                                    println!("  ‚úÖ Loaded: {}", model_name);
                                } else {
                                    println!(
                                        "  ‚ö†Ô∏è  Failed to load: {} (code: {})",
                                        model_name, load_result
                                    );
                                }
                                voicevox_voice_model_file_delete(model);
                            } else {
                                println!("  ‚ö†Ô∏è  Failed to open: {} (code: {})", model_name, result);
                            }
                        }
                    }
                }
            } else {
                println!("  ‚ö†Ô∏è  Model not found: {}", model_name);
            }
        }

        if loaded_count > 0 {
            println!("‚úÖ Successfully loaded {} default VVM models", loaded_count);
        } else {
            println!("‚ö†Ô∏è  No default VVM models were loaded");
        }

        Ok(())
    }

    fn load_specific_model(&self, model_name: &str) -> Result<()> {
        let models_dir = find_models_dir()?;
        let model_path = models_dir.join(format!("{}.vvm", model_name));

        if !model_path.exists() {
            return Err(anyhow!("Model not found: {}.vvm", model_name));
        }

        println!("üì¶ Loading model: {}.vvm", model_name);

        if let Some(path_str) = model_path.to_str() {
            if let Ok(path_cstr) = CString::new(path_str) {
                unsafe {
                    let mut model: *mut VoicevoxVoiceModelFile = ptr::null_mut();
                    let result = voicevox_voice_model_file_open(path_cstr.as_ptr(), &mut model);
                    if result == VOICEVOX_RESULT_OK {
                        let load_result =
                            voicevox_synthesizer_load_voice_model(self.synthesizer, model);
                        if load_result == VOICEVOX_RESULT_OK {
                            println!("  ‚úÖ Successfully loaded: {}.vvm", model_name);
                        } else if load_result == 18 {
                            // MODEL_ALREADY_LOADED_ERROR
                            // Model already loaded, this is OK
                            println!("  ‚ÑπÔ∏è  Model {}.vvm already loaded", model_name);
                        } else {
                            voicevox_voice_model_file_delete(model);
                            return Err(anyhow!(
                                "Failed to load model: {} (code: {})",
                                model_name,
                                load_result
                            ));
                        }
                        voicevox_voice_model_file_delete(model);
                    } else {
                        return Err(anyhow!(
                            "Failed to open model: {} (code: {})",
                            model_name,
                            result
                        ));
                    }
                }
            }
        }
        Ok(())
    }

    fn load_models(synthesizer: *mut VoicevoxSynthesizer) -> Result<()> {
        // Find the models directory
        let models_dir = find_models_dir()?;

        println!("üì¶ Loading VVM models from: {}", models_dir.display());

        // Load all VVM files
        let mut loaded_count = 0;
        if let Ok(entries) = std::fs::read_dir(&models_dir) {
            for entry in entries.filter_map(|e| e.ok()) {
                if let Some(file_name) = entry.file_name().to_str() {
                    if file_name.ends_with(".vvm") {
                        let model_path = entry.path();
                        if let Some(path_str) = model_path.to_str() {
                            if let Ok(path_cstr) = CString::new(path_str) {
                                unsafe {
                                    // Try to load the model
                                    let mut model: *mut VoicevoxVoiceModelFile = ptr::null_mut();
                                    let result = voicevox_voice_model_file_open(
                                        path_cstr.as_ptr(),
                                        &mut model,
                                    );
                                    if result == VOICEVOX_RESULT_OK {
                                        let load_result = voicevox_synthesizer_load_voice_model(
                                            synthesizer,
                                            model,
                                        );
                                        if load_result == VOICEVOX_RESULT_OK {
                                            loaded_count += 1;
                                            println!("  ‚úÖ Loaded: {}", file_name);
                                        } else {
                                            println!(
                                                "  ‚ö†Ô∏è  Failed to load: {} (code: {})",
                                                file_name, load_result
                                            );
                                        }
                                        voicevox_voice_model_file_delete(model);
                                    } else {
                                        println!(
                                            "  ‚ö†Ô∏è  Failed to open: {} (code: {})",
                                            file_name, result
                                        );
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        if loaded_count > 0 {
            println!("‚úÖ Successfully loaded {} VVM models", loaded_count);
        } else {
            println!("‚ö†Ô∏è  No VVM models were loaded");
        }

        Ok(())
    }

    fn synthesize_simple(&self, text: &str, style_id: VoicevoxStyleId) -> Result<Vec<u8>> {
        unsafe {
            let text_cstr = CString::new(text)?;
            let tts_options = voicevox_make_default_tts_options();
            let mut wav_data: *mut u8 = ptr::null_mut();
            let mut wav_length: usize = 0;

            let result = voicevox_synthesizer_tts(
                self.synthesizer,
                text_cstr.as_ptr(),
                style_id,
                tts_options,
                &mut wav_length,
                &mut wav_data,
            );

            if result != VOICEVOX_RESULT_OK {
                return Err(anyhow!("Speech synthesis failed: code {}", result));
            }

            if wav_data.is_null() || wav_length == 0 {
                return Err(anyhow!("Audio data was not generated"));
            }

            let wav_vec = std::slice::from_raw_parts(wav_data, wav_length).to_vec();
            voicevox_wav_free(wav_data);
            Ok(wav_vec)
        }
    }

    fn synthesize_streaming(&self, text: &str, style_id: VoicevoxStyleId) -> Result<()> {
        self.synthesize_streaming_with_config(text, style_id, 100, None)
    }

    fn synthesize_streaming_with_config(
        &self,
        text: &str,
        style_id: VoicevoxStyleId,
        delay_ms: u64,
        chunk_size: Option<usize>,
    ) -> Result<()> {
        // „ÉÜ„Ç≠„Çπ„Éà„ÇíÈÅ©Âàá„Å™„Çµ„Ç§„Ç∫„Å´ÂàÜÂâ≤
        let sentences = if let Some(size) = chunk_size {
            split_text_by_size(text, size)
        } else {
            split_sentences(text)
        };

        // „Ç™„Éº„Éá„Ç£„Ç™„Çπ„Éà„É™„Éº„É†„Å®„Ç∑„É≥„ÇØ„ÇíÂàùÊúüÂåñ
        let (_stream, stream_handle) = OutputStream::try_default()
            .map_err(|e| anyhow!("Failed to create audio stream: {}", e))?;
        let sink = Sink::try_new(&stream_handle)
            .map_err(|e| anyhow!("Failed to create audio sink: {}", e))?;

        println!(
            "üéµ Starting streaming synthesis for {} segments...",
            sentences.len()
        );
        if chunk_size.is_some() {
            println!(
                "   üìè Using character-based chunking (max {} chars per chunk)",
                chunk_size.unwrap()
            );
        } else {
            println!("   ÔøΩ Using sentence-based chunking");
        }
        println!("   ‚è±Ô∏è  Delay between segments: {}ms", delay_ms);

        let start_time = std::time::Instant::now();
        let mut total_synthesis_time = std::time::Duration::ZERO;

        // ÂêÑ„Çª„Ç∞„É°„É≥„Éà„ÇíÈ†ÜÊ¨°ÂêàÊàê„ÉªÂÜçÁîü
        for (i, segment) in sentences.iter().enumerate() {
            if segment.trim().is_empty() {
                continue;
            }

            let segment_display = if segment.len() > 30 {
                format!("{}...", &segment[..30])
            } else {
                segment.clone()
            };

            println!(
                "  üîä [{}/{}] Processing: \"{}\"",
                i + 1,
                sentences.len(),
                segment_display
            );

            let synthesis_start = std::time::Instant::now();
            // Èü≥Â£∞ÂêàÊàê
            let wav_data = self.synthesize_simple(segment, style_id)?;
            let synthesis_time = synthesis_start.elapsed();
            total_synthesis_time += synthesis_time;

            // WAV„Éá„Éº„Çø„ÇíÈü≥Â£∞„Éá„Ç≥„Éº„ÉÄ„Éº„Å´Â§âÊèõ
            let cursor = Cursor::new(wav_data);
            match Decoder::new(cursor) {
                Ok(source) => {
                    // Èü≥Â£∞„Çí„Ç≠„É•„Éº„Å´ËøΩÂä†Ôºà„Éé„É≥„Éñ„É≠„ÉÉ„Ç≠„É≥„Ç∞Ôºâ
                    sink.append(source);

                    println!("    ‚ö° Synthesis: {:?}, Audio queued", synthesis_time);

                    // Ë®≠ÂÆö„Åï„Çå„ÅüÈñìÈöî„ÅßÂæÖÊ©ü
                    if delay_ms > 0 {
                        std::thread::sleep(std::time::Duration::from_millis(delay_ms));
                    }
                }
                Err(e) => {
                    println!("  ‚ö†Ô∏è  Failed to decode audio for segment {}: {}", i + 1, e);
                }
            }
        }

        // ÂÖ®„Å¶„ÅÆÈü≥Â£∞„ÅåÂÜçÁîü„Åï„Çå„Çã„Åæ„ÅßÂæÖÊ©ü
        println!("‚è≥ Waiting for audio playback to complete...");
        sink.sleep_until_end();

        let total_time = start_time.elapsed();
        println!("‚úÖ Streaming synthesis completed!");
        println!(
            "   üìä Total time: {:?}, Synthesis time: {:?}, Efficiency: {:.1}%",
            total_time,
            total_synthesis_time,
            (total_synthesis_time.as_secs_f64() / total_time.as_secs_f64()) * 100.0
        );
        Ok(())
    }

    fn get_speakers(&self) -> Result<Vec<Speaker>> {
        unsafe {
            let metas_json = voicevox_synthesizer_create_metas_json(self.synthesizer);
            if metas_json.is_null() {
                return Err(anyhow!("Failed to get speaker metadata"));
            }

            let metas_str = CStr::from_ptr(metas_json).to_str()?;
            let speakers: Vec<Speaker> = serde_json::from_str(metas_str)
                .map_err(|e| anyhow!("Failed to parse speaker metadata: {}", e))?;

            voicevox_json_free(metas_json);
            Ok(speakers)
        }
    }
}

impl Drop for VoicevoxCore {
    fn drop(&mut self) {
        unsafe {
            if !self.synthesizer.is_null() {
                voicevox_synthesizer_delete(self.synthesizer);
            }
            if !self._open_jtalk_rc.is_null() {
                voicevox_open_jtalk_rc_delete(self._open_jtalk_rc);
            }
        }
    }
}

// Helper function to find VVM models directory
fn find_models_dir() -> Result<PathBuf> {
    // Priority 1: Package installation path (when used as a Nix package)
    if let Ok(exe_path) = std::env::current_exe() {
        if let Some(pkg_root) = exe_path.parent().and_then(|p| p.parent()) {
            let pkg_models_path = pkg_root.join("share/voicevox/models");
            if pkg_models_path.exists() {
                return Ok(pkg_models_path);
            }
        }
    }

    // Priority 2: Development/workspace paths
    let workspace_root = std::env::current_dir()
        .ok()
        .and_then(|current_dir| {
            current_dir
                .ancestors()
                .find(|a| a.join("voicevox_models").exists())
                .map(|p| p.to_path_buf())
        })
        .unwrap_or_else(|| PathBuf::from("/Users/gen/Documents/usabarashi/mynix"));

    let models_dir = workspace_root.join("voicevox_models/models/vvms");
    if models_dir.exists() {
        Ok(models_dir)
    } else {
        // Priority 3: Environment variable (fallback)
        if let Ok(models_dir) = std::env::var("VOICEVOX_MODELS_DIR") {
            let models_path = PathBuf::from(&models_dir);
            if models_path.exists() {
                return Ok(models_path);
            }
        }
        Err(anyhow!("VVM models directory not found. Checked paths: package path, workspace path, environment VOICEVOX_MODELS_DIR"))
    }
}

// Helper function to check if a directory contains .dic files
fn has_dic_files(dict_path: &PathBuf) -> bool {
    if let Ok(entries) = std::fs::read_dir(dict_path) {
        entries.filter_map(|e| e.ok()).any(|e| {
            if let Some(file_name) = e.file_name().to_str() {
                file_name.ends_with(".dic")
            } else {
                false
            }
        })
    } else {
        false
    }
}

fn find_openjtalk_dict() -> Result<String> {
    // Priority 1: Package installation path (when used as a Nix package)
    if let Ok(exe_path) = std::env::current_exe() {
        if let Some(pkg_root) = exe_path.parent().and_then(|p| p.parent()) {
            let pkg_dict_path = pkg_root.join("share/voicevox/dict");
            if pkg_dict_path.exists() && has_dic_files(&pkg_dict_path) {
                let path_str = pkg_dict_path.to_string_lossy().to_string();
                println!("Found OpenJTalk dictionary (package): {}", path_str);
                return Ok(path_str);
            }
        }
    }

    // Priority 2: Development/workspace paths
    let workspace_root = std::env::current_dir()
        .ok()
        .and_then(|current_dir| {
            current_dir
                .ancestors()
                .find(|a| a.join("voicevox_models").exists())
                .map(|p| p.to_path_buf())
        })
        .unwrap_or_else(|| PathBuf::from("/Users/gen/Documents/usabarashi/mynix"));

    let possible_dict_paths = vec![
        workspace_root
            .join("voicevox_models/dict/open_jtalk_dic_utf_8-1.11")
            .to_string_lossy()
            .to_string(),
        workspace_root
            .join("dict/open_jtalk_dic_utf_8-1.11")
            .to_string_lossy()
            .to_string(),
        // System fallback paths
        "/opt/homebrew/share/open-jtalk/dic".to_string(),
        "/usr/local/share/open-jtalk/dic".to_string(),
        "/opt/local/share/open-jtalk/dic".to_string(),
        "/usr/share/open-jtalk/dic".to_string(),
        "./dict".to_string(),
    ];

    for path in &possible_dict_paths {
        let dict_path = PathBuf::from(path);
        if dict_path.exists() {
            // Check for .dic files
            if let Ok(entries) = std::fs::read_dir(&dict_path) {
                let has_dic_files = entries.filter_map(|e| e.ok()).any(|e| {
                    if let Some(file_name) = e.file_name().to_str() {
                        file_name.ends_with(".dic")
                    } else {
                        false
                    }
                });

                if has_dic_files {
                    println!("Found OpenJTalk dictionary: {}", path);
                    return Ok(path.to_string());
                }
            }
        }
    }

    // Priority 3: Environment variable (fallback)
    if let Ok(dict_dir) = std::env::var("VOICEVOX_DICT_DIR") {
        let dict_path = PathBuf::from(&dict_dir);
        if dict_path.exists() && has_dic_files(&dict_path) {
            println!("Found OpenJTalk dictionary (env fallback): {}", dict_dir);
            return Ok(dict_dir);
        }
    }

    Err(anyhow!(
        "OpenJTalk dictionary not found.\nChecked paths: {:?}",
        possible_dict_paths
    ))
}

// Èü≥Â£∞ID„Åã„ÇâÂøÖË¶Å„Å™VVM„É¢„Éá„É´Áï™Âè∑„ÇíÂèñÂæó
fn get_model_for_voice_id(voice_id: u32) -> Option<u32> {
    match voice_id {
        // „Åö„Çì„Å†„ÇÇ„Çì (3.vvm)
        1 | 3 | 7 => Some(3),
        // ÂõõÂõΩ„ÇÅ„Åü„Çì (2.vvm)
        2 | 0 | 6 | 4 => Some(2),
        // Êò•Êó•ÈÉ®„Å§„ÇÄ„Åé (8.vvm)
        8 | 83 | 84 => Some(8),
        // Èõ®Êô¥„ÅØ„ÅÜ (10.vvm)
        10 | 85 => Some(10),
        // Ê≥¢Èü≥„É™„ÉÑ (9.vvm)
        9 | 65 => Some(9),
        // ÁéÑÈáéÊ≠¶ÂÆè (11.vvm)
        11 | 39 | 40 | 41 => Some(11),
        // ÁôΩ‰∏äËôéÂ§™ÈÉé (12.vvm)
        12 | 32 | 33 => Some(12),
        // ÈùíÂ±±ÈæçÊòü (13.vvm)
        13 | 86 | 87 | 88 | 89 | 90 => Some(13),
        // ÂÜ•È≥¥„Å≤„Åæ„Çä (14.vvm)
        14 => Some(14),
        // ‰πùÂ∑û„Åù„Çâ (16.vvm)
        15 | 16 | 17 | 18 | 19 => Some(16),
        // „ÇÇ„Å°Â≠ê„Åï„Çì (17.vvm)
        20 => Some(17),
        // Ââ£Â¥éÈõåÈõÑ (18.vvm)
        21 => Some(18),
        // „Éá„Éï„Ç©„É´„Éà„ÅØ‰∏çÊòé
        _ => None,
    }
}

// Èü≥Â£∞Âêç„Åã„Çâ„Çπ„Çø„Ç§„É´ID„Å∏„ÅÆ„Éû„ÉÉ„Éî„É≥„Ç∞
fn get_voice_mapping() -> HashMap<&'static str, (u32, &'static str)> {
    let mut voices = HashMap::new();

    // „Åö„Çì„Å†„ÇÇ„ÇìÔºàÂÖ®„É¢„Éº„ÉâÔºâ
    voices.insert("zundamon", (3, "„Åö„Çì„Å†„ÇÇ„Çì („Éé„Éº„Éû„É´)"));
    voices.insert("zundamon-normal", (3, "„Åö„Çì„Å†„ÇÇ„Çì („Éé„Éº„Éû„É´)"));
    voices.insert("zundamon-amama", (1, "„Åö„Çì„Å†„ÇÇ„Çì („ÅÇ„Åæ„ÅÇ„Åæ)"));
    voices.insert("zundamon-tsundere", (7, "„Åö„Çì„Å†„ÇÇ„Çì („ÉÑ„É≥„ÉÑ„É≥)"));
    voices.insert("zundamon-sexy", (5, "„Åö„Çì„Å†„ÇÇ„Çì („Çª„ÇØ„Ç∑„Éº)"));
    voices.insert("zundamon-whisper", (22, "„Åö„Çì„Å†„ÇÇ„Çì („Åï„Åï„ÇÑ„Åç)"));
    voices.insert("zundamon-excited", (38, "„Åö„Çì„Å†„ÇÇ„Çì („Éò„É≠„Éò„É≠)"));

    // ÂõõÂõΩ„ÇÅ„Åü„ÇìÔºàÂÖ®„É¢„Éº„ÉâÔºâ
    voices.insert("metan", (2, "ÂõõÂõΩ„ÇÅ„Åü„Çì („Éé„Éº„Éû„É´)"));
    voices.insert("metan-normal", (2, "ÂõõÂõΩ„ÇÅ„Åü„Çì („Éé„Éº„Éû„É´)"));
    voices.insert("metan-amama", (0, "ÂõõÂõΩ„ÇÅ„Åü„Çì („ÅÇ„Åæ„ÅÇ„Åæ)"));
    voices.insert("metan-tsundere", (6, "ÂõõÂõΩ„ÇÅ„Åü„Çì („ÉÑ„É≥„ÉÑ„É≥)"));
    voices.insert("metan-sexy", (4, "ÂõõÂõΩ„ÇÅ„Åü„Çì („Çª„ÇØ„Ç∑„Éº)"));
    voices.insert("metan-whisper", (36, "ÂõõÂõΩ„ÇÅ„Åü„Çì („Åï„Åï„ÇÑ„Åç)"));
    voices.insert("metan-excited", (37, "ÂõõÂõΩ„ÇÅ„Åü„Çì („Éò„É≠„Éò„É≠)"));

    // Êò•Êó•ÈÉ®„Å§„ÇÄ„Åé
    voices.insert("tsumugi", (8, "Êò•Êó•ÈÉ®„Å§„ÇÄ„Åé („Éé„Éº„Éû„É´)"));
    voices.insert("tsumugi-normal", (8, "Êò•Êó•ÈÉ®„Å§„ÇÄ„Åé („Éé„Éº„Éû„É´)"));

    // Èõ®Êô¥„ÅØ„ÅÜ
    voices.insert("hau", (10, "Èõ®Êô¥„ÅØ„ÅÜ („Éé„Éº„Éû„É´)"));
    voices.insert("hau-normal", (10, "Èõ®Êô¥„ÅØ„ÅÜ („Éé„Éº„Éû„É´)"));

    // Ê≥¢Èü≥„É™„ÉÑ
    voices.insert("ritsu", (9, "Ê≥¢Èü≥„É™„ÉÑ („Éé„Éº„Éû„É´)"));
    voices.insert("ritsu-normal", (9, "Ê≥¢Èü≥„É™„ÉÑ („Éé„Éº„Éû„É´)"));

    // ÁéÑÈáéÊ≠¶ÂÆè
    voices.insert("takehiro", (11, "ÁéÑÈáéÊ≠¶ÂÆè („Éé„Éº„Éû„É´)"));
    voices.insert("takehiro-normal", (11, "ÁéÑÈáéÊ≠¶ÂÆè („Éé„Éº„Éû„É´)"));
    voices.insert("takehiro-excited", (39, "ÁéÑÈáéÊ≠¶ÂÆè (Âñú„Å≥)"));
    voices.insert("takehiro-tsundere", (40, "ÁéÑÈáéÊ≠¶ÂÆè („ÉÑ„É≥„ÇÆ„É¨)"));
    voices.insert("takehiro-sad", (41, "ÁéÑÈáéÊ≠¶ÂÆè (ÊÇ≤„Åó„Åø)"));

    // ÁôΩ‰∏äËôéÂ§™ÈÉé
    voices.insert("kohtaro", (12, "ÁôΩ‰∏äËôéÂ§™ÈÉé („Åµ„Å§„ÅÜ)"));
    voices.insert("kohtaro-normal", (12, "ÁôΩ‰∏äËôéÂ§™ÈÉé („Åµ„Å§„ÅÜ)"));
    voices.insert("kohtaro-excited", (32, "ÁôΩ‰∏äËôéÂ§™ÈÉé („Çè„Éº„ÅÑ)"));
    voices.insert("kohtaro-angry", (33, "ÁôΩ‰∏äËôéÂ§™ÈÉé („Å≥„Åè„Å≥„Åè)"));

    // ÈùíÂ±±ÈæçÊòü
    voices.insert("ryusei", (13, "ÈùíÂ±±ÈæçÊòü („Éé„Éº„Éû„É´)"));
    voices.insert("ryusei-normal", (13, "ÈùíÂ±±ÈæçÊòü („Éé„Éº„Éû„É´)"));
    voices.insert("ryusei-excited", (86, "ÈùíÂ±±ÈæçÊòü (ÁÜ±Ë°Ä)"));
    voices.insert("ryusei-cool", (87, "ÈùíÂ±±ÈæçÊòü (‰∏çÊ©üÂ´å)"));
    voices.insert("ryusei-sad", (88, "ÈùíÂ±±ÈæçÊòü (Âñú„Å≥)"));
    voices.insert("ryusei-surprised", (89, "ÈùíÂ±±ÈæçÊòü („Åó„Å£„Å®„Çä)"));
    voices.insert("ryusei-whisper", (90, "ÈùíÂ±±ÈæçÊòü („Åã„Å™„Åó„Åø)"));

    // ÂÜ•È≥¥„Å≤„Åæ„Çä
    voices.insert("himari", (14, "ÂÜ•È≥¥„Å≤„Åæ„Çä („Éé„Éº„Éû„É´)"));
    voices.insert("himari-normal", (14, "ÂÜ•È≥¥„Å≤„Åæ„Çä („Éé„Éº„Éû„É´)"));

    // ‰πùÂ∑û„Åù„Çâ
    voices.insert("sora", (16, "‰πùÂ∑û„Åù„Çâ („Éé„Éº„Éû„É´)"));
    voices.insert("sora-normal", (16, "‰πùÂ∑û„Åù„Çâ („Éé„Éº„Éû„É´)"));
    voices.insert("sora-amama", (15, "‰πùÂ∑û„Åù„Çâ („ÅÇ„Åæ„ÅÇ„Åæ)"));
    voices.insert("sora-tsundere", (18, "‰πùÂ∑û„Åù„Çâ („ÉÑ„É≥„ÉÑ„É≥)"));
    voices.insert("sora-sexy", (17, "‰πùÂ∑û„Åù„Çâ („Çª„ÇØ„Ç∑„Éº)"));
    voices.insert("sora-whisper", (19, "‰πùÂ∑û„Åù„Çâ („Åï„Åï„ÇÑ„Åç)"));

    // „ÇÇ„Å°Â≠ê„Åï„Çì
    voices.insert("mochiko", (20, "„ÇÇ„Å°Â≠ê„Åï„Çì („Éé„Éº„Éû„É´)"));
    voices.insert("mochiko-normal", (20, "„ÇÇ„Å°Â≠ê„Åï„Çì („Éé„Éº„Éû„É´)"));

    // Ââ£Â¥éÈõåÈõÑ
    voices.insert("menou", (21, "Ââ£Â¥éÈõåÈõÑ („Éé„Éº„Éû„É´)"));
    voices.insert("menou-normal", (21, "Ââ£Â¥éÈõåÈõÑ („Éé„Éº„Éû„É´)"));

    // „Éá„Éï„Ç©„É´„Éà„Ç®„Ç§„É™„Ç¢„Çπ
    voices.insert("default", (3, "„Åö„Çì„Å†„ÇÇ„Çì („Éé„Éº„Éû„É´)"));

    voices
}

fn resolve_voice_name_with_core(voice_name: &str, core: &VoicevoxCore) -> Result<(u32, String)> {
    let voices = get_voice_mapping();

    // Èü≥Â£∞‰∏ÄË¶ßË°®Á§∫„ÅÆÁâπÂà•„Å™„Ç±„Éº„Çπ
    if voice_name == "?" {
        println!("üé≠ Available VOICEVOX voices:");
        println!();

        // „Ç≠„É£„É©„ÇØ„Çø„ÉºÂà•„Å´„Ç∞„É´„Éº„ÉóÂåñ„Åó„Å¶Ë°®Á§∫
        println!("  üìù „Åö„Çì„Å†„ÇÇ„Çì:");
        println!("    zundamon, zundamon-normal    (ID: 3)  - „Åö„Çì„Å†„ÇÇ„Çì („Éé„Éº„Éû„É´)");
        println!("    zundamon-amama              (ID: 1)  - „Åö„Çì„Å†„ÇÇ„Çì („ÅÇ„Åæ„ÅÇ„Åæ)");
        println!("    zundamon-tsundere           (ID: 7)  - „Åö„Çì„Å†„ÇÇ„Çì („ÉÑ„É≥„ÉÑ„É≥)");
        println!("    zundamon-sexy               (ID: 5)  - „Åö„Çì„Å†„ÇÇ„Çì („Çª„ÇØ„Ç∑„Éº)");
        println!("    zundamon-whisper            (ID: 22) - „Åö„Çì„Å†„ÇÇ„Çì („Åï„Åï„ÇÑ„Åç)");
        println!("    zundamon-excited            (ID: 38) - „Åö„Çì„Å†„ÇÇ„Çì („Éò„É≠„Éò„É≠)");
        println!();

        println!("  üçä ÂõõÂõΩ„ÇÅ„Åü„Çì:");
        println!("    metan, metan-normal         (ID: 2)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („Éé„Éº„Éû„É´)");
        println!("    metan-amama                 (ID: 0)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („ÅÇ„Åæ„ÅÇ„Åæ)");
        println!("    metan-tsundere              (ID: 6)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („ÉÑ„É≥„ÉÑ„É≥)");
        println!("    metan-sexy                  (ID: 4)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („Çª„ÇØ„Ç∑„Éº)");
        println!("    metan-whisper               (ID: 36) - ÂõõÂõΩ„ÇÅ„Åü„Çì („Åï„Åï„ÇÑ„Åç)");
        println!("    metan-excited               (ID: 37) - ÂõõÂõΩ„ÇÅ„Åü„Çì („Éò„É≠„Éò„É≠)");
        println!();

        println!("  üå∏ „Åù„ÅÆ‰ªñ„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„Éº:");
        println!("    tsumugi                     (ID: 8)  - Êò•Êó•ÈÉ®„Å§„ÇÄ„Åé („Éé„Éº„Éû„É´)");
        println!("    hau                         (ID: 10) - Èõ®Êô¥„ÅØ„ÅÜ („Éé„Éº„Éû„É´)");
        println!("    ritsu                       (ID: 9)  - Ê≥¢Èü≥„É™„ÉÑ („Éé„Éº„Éû„É´)");
        println!("    takehiro                    (ID: 11) - ÁéÑÈáéÊ≠¶ÂÆè („Éé„Éº„Éû„É´)");
        println!("    kohtaro                     (ID: 12) - ÁôΩ‰∏äËôéÂ§™ÈÉé („Åµ„Å§„ÅÜ)");
        println!("    ryusei                      (ID: 13) - ÈùíÂ±±ÈæçÊòü („Éé„Éº„Éû„É´)");
        println!("    sora                        (ID: 16) - ‰πùÂ∑û„Åù„Çâ („Éé„Éº„Éû„É´)");
        println!();

        println!("Usage: voicevox-say --voice <voice_name> \"your text\"");
        println!("Example: voicevox-say --voice zundamon \"„Åì„Çì„Å´„Å°„ÅØ\"");
        println!();
        println!("üí° Tip: Use --load-all-models to preload all voice models for faster synthesis.");
        println!("üí° Tip: Default models (zundamon, metan, tsumugi) are loaded automatically.");

        std::process::exit(0);
    }

    // Áõ¥Êé•‰∏ÄËá¥„Åô„Çã„Éú„Ç§„ÇπÂêç„ÇíÊé¢„Åô
    if let Some(&(style_id, description)) = voices.get(voice_name) {
        return Ok((style_id, description.to_string()));
    }

    // Êï∞ÂÄ§„Å®„Åó„Å¶Ëß£Êûê„ÇíË©¶„Åø„Çã
    if let Ok(style_id) = voice_name.parse::<u32>() {
        return Ok((style_id, format!("Style ID {}", style_id)));
    }

    Err(anyhow!(
        "Unknown voice: {}. Use --voice ? to list available voices.",
        voice_name
    ))
}

fn resolve_voice_name(voice_name: &str) -> Result<(u32, String)> {
    let voices = get_voice_mapping();

    // Èü≥Â£∞‰∏ÄË¶ßË°®Á§∫„ÅÆÁâπÂà•„Å™„Ç±„Éº„Çπ
    if voice_name == "?" {
        println!("üé≠ Available VOICEVOX voices:");
        println!();

        // „Ç≠„É£„É©„ÇØ„Çø„ÉºÂà•„Å´„Ç∞„É´„Éº„ÉóÂåñ„Åó„Å¶Ë°®Á§∫
        println!("  üìù „Åö„Çì„Å†„ÇÇ„Çì:");
        println!("    zundamon, zundamon-normal    (ID: 3)  - „Åö„Çì„Å†„ÇÇ„Çì („Éé„Éº„Éû„É´)");
        println!("    zundamon-amama              (ID: 1)  - „Åö„Çì„Å†„ÇÇ„Çì („ÅÇ„Åæ„ÅÇ„Åæ)");
        println!("    zundamon-tsundere           (ID: 7)  - „Åö„Çì„Å†„ÇÇ„Çì („ÉÑ„É≥„ÉÑ„É≥)");
        println!("    zundamon-sexy               (ID: 5)  - „Åö„Çì„Å†„ÇÇ„Çì („Çª„ÇØ„Ç∑„Éº)");
        println!("    zundamon-whisper            (ID: 22) - „Åö„Çì„Å†„ÇÇ„Çì („Åï„Åï„ÇÑ„Åç)");
        println!("    zundamon-excited            (ID: 38) - „Åö„Çì„Å†„ÇÇ„Çì („Éò„É≠„Éò„É≠)");
        println!();

        println!("  üçä ÂõõÂõΩ„ÇÅ„Åü„Çì:");
        println!("    metan, metan-normal         (ID: 2)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („Éé„Éº„Éû„É´)");
        println!("    metan-amama                 (ID: 0)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („ÅÇ„Åæ„ÅÇ„Åæ)");
        println!("    metan-tsundere              (ID: 6)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („ÉÑ„É≥„ÉÑ„É≥)");
        println!("    metan-sexy                  (ID: 4)  - ÂõõÂõΩ„ÇÅ„Åü„Çì („Çª„ÇØ„Ç∑„Éº)");
        println!("    metan-whisper               (ID: 36) - ÂõõÂõΩ„ÇÅ„Åü„Çì („Åï„Åï„ÇÑ„Åç)");
        println!("    metan-excited               (ID: 37) - ÂõõÂõΩ„ÇÅ„Åü„Çì („Éò„É≠„Éò„É≠)");
        println!();

        println!("  üå∏ „Åù„ÅÆ‰ªñ„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„Éº:");
        println!("    tsumugi                     (ID: 8)  - Êò•Êó•ÈÉ®„Å§„ÇÄ„Åé („Éé„Éº„Éû„É´)");
        println!("    hau                         (ID: 10) - Èõ®Êô¥„ÅØ„ÅÜ („Éé„Éº„Éû„É´)");
        println!("    ritsu                       (ID: 9)  - Ê≥¢Èü≥„É™„ÉÑ („Éé„Éº„Éû„É´)");
        println!("    takehiro                    (ID: 11) - ÁéÑÈáéÊ≠¶ÂÆè („Éé„Éº„Éû„É´)");
        println!("    kohtaro                     (ID: 12) - ÁôΩ‰∏äËôéÂ§™ÈÉé („Åµ„Å§„ÅÜ)");
        println!("    ryusei                      (ID: 13) - ÈùíÂ±±ÈæçÊòü („Éé„Éº„Éû„É´)");
        println!("    sora                        (ID: 16) - ‰πùÂ∑û„Åù„Çâ („Éé„Éº„Éû„É´)");
        println!();

        println!("  üí° Tips:");
        println!("    - Êï∞ÂÄ§ID„ÇíÁõ¥Êé•ÊåáÂÆö„Åô„Çã„Åì„Å®„ÇÇÂèØËÉΩ„Åß„Åô: -v 3");
        println!("    - „Ç≠„É£„É©„ÇØ„Çø„ÉºÂêç„ÅÆ„Åø„Åß„Éá„Éï„Ç©„É´„Éà„É¢„Éº„Éâ„Çí‰ΩøÁî®: -v zundamon");
        println!("    - ÁâπÂÆö„ÅÆ„É¢„Éº„Éâ„ÇíÊåáÂÆö: -v zundamon-amama");
        println!();

        std::process::exit(0);
    }

    // Áõ¥Êé•ÁöÑ„Å™Êï∞ÂÄ§ÊåáÂÆö„Çí„Çµ„Éù„Éº„Éà
    if let Ok(style_id) = voice_name.parse::<u32>() {
        return Ok((style_id, format!("Style ID {}", style_id)));
    }

    // Èü≥Â£∞Âêç„Åã„ÇâÊ§úÁ¥¢
    if let Some((style_id, description)) = voices.get(voice_name) {
        Ok((*style_id, description.to_string()))
    } else {
        Err(anyhow!(
            "Unknown voice: '{}'. Use -v ? to list available voices.",
            voice_name
        ))
    }
}

// „ÉÜ„Ç≠„Çπ„ÉàÂÖ•Âäõ„ÇíÂèñÂæó„Åô„ÇãÈñ¢Êï∞
fn get_input_text(matches: &clap::ArgMatches) -> Result<String> {
    // „Ç≥„Éû„É≥„Éâ„É©„Ç§„É≥ÂºïÊï∞„Åã„Çâ
    if let Some(text) = matches.get_one::<String>("text") {
        return Ok(text.clone());
    }

    // „Éï„Ç°„Ç§„É´„Åã„Çâ
    if let Some(file_path) = matches.get_one::<String>("input-file") {
        if file_path == "-" {
            // Ê®ôÊ∫ñÂÖ•Âäõ„Åã„ÇâË™≠„ÅøÂèñ„Çä
            use std::io::{self, Read};
            let mut buffer = String::new();
            io::stdin().read_to_string(&mut buffer)?;
            return Ok(buffer.trim().to_string());
        } else {
            // „Éï„Ç°„Ç§„É´„Åã„ÇâË™≠„ÅøÂèñ„Çä
            return Ok(fs::read_to_string(file_path)?);
        }
    }

    // „ÉÜ„Ç≠„Çπ„Éà„Åå‰Ωï„ÇÇÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà„ÅØÊ®ôÊ∫ñÂÖ•Âäõ„Åã„Çâ
    use std::io::{self, Read};
    let mut buffer = String::new();
    io::stdin().read_to_string(&mut buffer)?;
    Ok(buffer.trim().to_string())
}

// „Éò„É´„Éë„ÉºÈñ¢Êï∞Ôºö„ÉÜ„Ç≠„Çπ„Éà„ÇíÊñá„Å´ÂàÜÂâ≤
fn split_sentences(text: &str) -> Vec<String> {
    let mut sentences = Vec::new();
    let mut current_sentence = String::new();

    for ch in text.chars() {
        current_sentence.push(ch);

        // Êñá„ÅÆÁµÇÁ´ØÊñáÂ≠ó„ÇíÊ§úÂá∫
        if ch == '„ÄÇ' || ch == 'ÔºÅ' || ch == 'Ôºü' || ch == '.' || ch == '!' || ch == '?' {
            if !current_sentence.trim().is_empty() {
                sentences.push(current_sentence.trim().to_string());
                current_sentence.clear();
            }
        }
    }

    // ÊÆã„Çä„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„Åå„ÅÇ„Çå„Å∞ËøΩÂä†
    if !current_sentence.trim().is_empty() {
        sentences.push(current_sentence.trim().to_string());
    }

    // Á©∫„ÅÆÊñá„ÇíÈô§Â§ñ
    sentences
        .into_iter()
        .filter(|s| !s.trim().is_empty())
        .collect()
}

// „Éò„É´„Éë„ÉºÈñ¢Êï∞Ôºö„ÉÜ„Ç≠„Çπ„Éà„ÇíÊåáÂÆö„Åó„ÅüÊñáÂ≠óÊï∞„ÅßÂàÜÂâ≤
fn split_text_by_size(text: &str, max_size: usize) -> Vec<String> {
    let mut chunks = Vec::new();
    let mut current_chunk = String::new();

    for word in text.split_whitespace() {
        if current_chunk.len() + word.len() + 1 > max_size && !current_chunk.is_empty() {
            chunks.push(current_chunk.trim().to_string());
            current_chunk.clear();
        }

        if !current_chunk.is_empty() {
            current_chunk.push(' ');
        }
        current_chunk.push_str(word);
    }

    if !current_chunk.trim().is_empty() {
        chunks.push(current_chunk.trim().to_string());
    }

    chunks
}

fn main() -> Result<()> {
    let app = Command::new("voicevox-say")
        .version(env!("CARGO_PKG_VERSION"))
        .about("ü´õ VOICEVOX Say - Convert text to audible speech using VOICEVOX")
        .arg(
            Arg::new("text")
                .help("Specify the text to speak on the command line")
                .index(1)
                .required(false),
        )
        .arg(
            Arg::new("voice")
                .help("Specify the voice to be used. Use '?' to list all available voices")
                .long("voice")
                .short('v')
                .value_name("VOICE")
                .default_value("zundamon"),
        )
        .arg(
            Arg::new("rate")
                .help("Speech rate multiplier (0.5-2.0, default: 1.0)")
                .long("rate")
                .short('r')
                .value_name("RATE")
                .value_parser(clap::value_parser!(f32))
                .default_value("1.0"),
        )
        .arg(
            Arg::new("output-file")
                .help("Specify the path for an audio file to be written")
                .long("output-file")
                .short('o')
                .value_name("FILE"),
        )
        .arg(
            Arg::new("input-file")
                .help("Specify a file to be spoken. Use '-' for stdin")
                .long("input-file")
                .short('f')
                .value_name("FILE"),
        )
        .arg(
            Arg::new("streaming")
                .help("Enable streaming synthesis (sentence-by-sentence)")
                .long("streaming")
                .action(clap::ArgAction::SetTrue),
        )
        .arg(
            Arg::new("quiet")
                .help("Don't play audio, only save to file")
                .long("quiet")
                .short('q')
                .action(clap::ArgAction::SetTrue),
        )
        .arg(
            Arg::new("list-speakers")
                .help("List all available speakers and styles from loaded models")
                .long("list-speakers")
                .action(clap::ArgAction::SetTrue),
        )
        .arg(
            Arg::new("speaker-id")
                .help("Directly specify speaker style ID (advanced users)")
                .long("speaker-id")
                .short('s')
                .value_name("ID")
                .value_parser(clap::value_parser!(u32))
                .conflicts_with("voice"),
        )
        .arg(
            Arg::new("load-all-models")
                .help("Load all available VVM models (slower startup, all voices available)")
                .long("load-all-models")
                .action(clap::ArgAction::SetTrue),
        );

    let matches = app.get_matches();

    // Èü≥Â£∞‰∏ÄË¶ßË°®Á§∫„ÅÆÂá¶ÁêÜÔºàÊó©Êúü„É™„Çø„Éº„É≥Ôºâ
    if let Some(voice_name) = matches.get_one::<String>("voice") {
        if voice_name == "?" {
            resolve_voice_name("?")?; // „Åì„Çå„ÅØÂÜÖÈÉ®„Åßexit(0)„Åô„Çã
        }
    }

    // Initialize VOICEVOX Core
    println!("üöÄ Initializing VOICEVOX Core...");
    let mut core = VoicevoxCore::new()?;

    // Load all models if requested
    if matches.get_flag("load-all-models") {
        println!("üì¶ Loading all VVM models (--load-all-models specified)...");
        if let Err(e) = VoicevoxCore::load_models(core.synthesizer) {
            println!("‚ö†Ô∏è  Warning: Failed to load some models: {}", e);
        }
    }

    println!("‚úÖ VOICEVOX Core initialized successfully");

    // Ë©≥Á¥∞„Å™„Çπ„Éî„Éº„Ç´„Éº‰∏ÄË¶ßË°®Á§∫
    if matches.get_flag("list-speakers") {
        println!("üìã All available speakers and styles from loaded models:");
        let speakers = core.get_speakers()?;
        for speaker in &speakers {
            println!("  üë§ {}", speaker.name);
            for style in &speaker.styles {
                println!("    üé≠ {} (ID: {})", style.name, style.id);
                if let Some(style_type) = &style.style_type {
                    println!("        Type: {}", style_type);
                }
            }
            println!();
        }
        return Ok(());
    }

    // „ÉÜ„Ç≠„Çπ„ÉàÂÖ•Âäõ„ÇíÂèñÂæó
    let text = get_input_text(&matches)?;
    if text.trim().is_empty() {
        return Err(anyhow!(
            "No text provided. Use command line argument, -f file, or pipe text to stdin."
        ));
    }

    // Èü≥Â£∞Ë®≠ÂÆö„ÇíËß£Ê±∫Ôºàspeaker-id„ÅåÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØ„Åù„Å°„Çâ„ÇíÂÑ™ÂÖàÔºâ
    let (style_id, voice_description) =
        if let Some(speaker_id) = matches.get_one::<u32>("speaker-id") {
            (*speaker_id, format!("Style ID {}", speaker_id))
        } else {
            let voice_name = matches.get_one::<String>("voice").unwrap();
            resolve_voice_name(voice_name)?
        };

    // Ë®≠ÂÆö„Éë„É©„É°„Éº„Çø
    let use_streaming = matches.get_flag("streaming");
    let rate = *matches.get_one::<f32>("rate").unwrap_or(&1.0);

    // „É¨„Éº„ÉàÁØÑÂõ≤„ÉÅ„Çß„ÉÉ„ÇØ
    if rate < 0.5 || rate > 2.0 {
        return Err(anyhow!("Rate must be between 0.5 and 2.0, got: {}", rate));
    }

    println!("üé≠ Voice: {}", voice_description);
    if rate != 1.0 {
        println!("‚ö° Rate: {}x", rate);
    }

    // ÂøÖË¶Å„Å™„É¢„Éá„É´„ÇíÂãïÁöÑ„Å´Ë™≠„ÅøËæº„ÅøÔºàÂêàÊàêÁõ¥Ââç„Å´ÂÆüË°åÔºâ
    if !matches.get_flag("load-all-models") {
        if let Some(model_num) = get_model_for_voice_id(style_id) {
            println!(
                "üì¶ Loading required model for style ID {}: {}.vvm",
                style_id, model_num
            );
            if let Err(e) = core.load_specific_model(&model_num.to_string()) {
                return Err(anyhow!(
                    "Failed to load required model for style ID {}: {}",
                    style_id,
                    e
                ));
            }
        } else {
            return Err(anyhow!("Unknown voice model required for style ID {}. Please ensure the voice model is available.", style_id));
        }
    }

    // Èü≥Â£∞ÂêàÊàê„ÅÆÂÆüË°å
    if use_streaming {
        println!("üéµ Starting streaming synthesis...");
        core.synthesize_streaming_with_config(&text, style_id, 100, None)?;
    } else {
        println!("üé§ Synthesizing speech...");
        let wav_data = core.synthesize_simple(&text, style_id)?;
        println!("‚úÖ Speech synthesis completed ({} bytes)", wav_data.len());

        // „Éï„Ç°„Ç§„É´Âá∫Âäõ
        if let Some(output_file) = matches.get_one::<String>("output-file") {
            fs::write(output_file, &wav_data)?;
            println!("üíæ Audio saved to: {}", output_file);
        }

        // Èü≥Â£∞ÂÜçÁîüÔºàquiet„É¢„Éº„Éâ„Åß„Å™„ÅÑÂ†¥ÂêàÔºâ
        if !matches.get_flag("quiet") && matches.get_one::<String>("output-file").is_none() {
            let temp_file = "/tmp/voicevox_say_temp.wav";
            fs::write(temp_file, &wav_data)?;

            // macOSÊ®ôÊ∫ñ„ÅÆafplay„ÅßÂÜçÁîü
            if let Ok(_) = std::process::Command::new("afplay").arg(temp_file).output() {
                // ÊàêÂäüÊôÇ„ÅØ‰Ωï„ÇÇË°®Á§∫„Åó„Å™„ÅÑÔºàsay„Ç≥„Éû„É≥„Éâ„Å®ÂêåÊßòÔºâ
            } else if let Ok(_) = std::process::Command::new("play").arg(temp_file).output() {
                // sox„Åß„ÅÆÂÜçÁîü„ÇÇ„Çµ„Ç§„É¨„É≥„Éà
            } else {
                eprintln!("Warning: No audio player found. Install sox or use -o to save file");
            }

            // ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„ÅÆÂâäÈô§
            let _ = fs::remove_file(temp_file);
        }
    }

    Ok(())
}
