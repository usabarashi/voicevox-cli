use anyhow::{anyhow, Result};
use clap::{Arg, Command};
use rodio::{Decoder, OutputStream, Sink};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::ffi::{CStr, CString};
use std::fs;
use std::io::Cursor;
use std::path::PathBuf;
use std::ptr;

// Use bindgen-generated bindings if available
#[cfg(feature = "use_bindgen")]
include!(concat!(env!("OUT_DIR"), "/bindings.rs"));

// Define constants for result codes (bindgen may not expose them properly)
#[cfg(feature = "use_bindgen")]
pub const VOICEVOX_RESULT_OK: i32 = 0;

// If bindgen fails, provide manual bindings (simplified)
#[cfg(not(feature = "use_bindgen"))]
mod manual_bindings {
    use libc::{c_char, c_int, c_uchar, c_uint, uintptr_t};

    pub const VOICEVOX_RESULT_OK: c_int = 0;
    pub type VoicevoxStyleId = c_uint;

    // Acceleration mode enum for macOS CPU-only processing
    #[repr(C)]
    #[derive(Clone, Copy)]
    pub enum VoicevoxAccelerationMode {
        Auto = 0,
        Cpu = 1,
        Gpu = 2,
    }

    // Initialize options structure for CPU-only mode
    #[repr(C)]
    #[derive(Clone, Copy)]
    pub struct VoicevoxInitializeOptions {
        pub acceleration_mode: VoicevoxAccelerationMode,
        pub cpu_num_threads: u16,
    }

    // Opaque types
    pub enum VoicevoxSynthesizer {}
    pub enum VoicevoxOnnxruntime {}
    pub enum OpenJtalkRc {}
    pub enum VoicevoxLoadOnnxruntimeOptions {}
    pub enum VoicevoxTtsOptions {}
    pub enum VoicevoxSynthesisOptions {}
    pub enum VoicevoxVoiceModelFile {}

    extern "C" {
        // Core initialization functions
        pub fn voicevox_make_default_load_onnxruntime_options(
        ) -> *const VoicevoxLoadOnnxruntimeOptions;
        pub fn voicevox_onnxruntime_load_once(
            options: *const VoicevoxLoadOnnxruntimeOptions,
            onnxruntime: *mut *const VoicevoxOnnxruntime,
        ) -> c_int;

        pub fn voicevox_open_jtalk_rc_new(
            open_jtalk_dic_dir: *const c_char,
            open_jtalk_rc: *mut *mut OpenJtalkRc,
        ) -> c_int;

        // Initialize options with CPU-only mode
        pub fn voicevox_synthesizer_new(
            onnxruntime: *const VoicevoxOnnxruntime,
            open_jtalk_rc: *mut OpenJtalkRc,
            options: VoicevoxInitializeOptions,
            synthesizer: *mut *mut VoicevoxSynthesizer,
        ) -> c_int;

        // TTS functions
        pub fn voicevox_make_default_tts_options() -> *const VoicevoxTtsOptions;
        pub fn voicevox_synthesizer_tts(
            synthesizer: *mut VoicevoxSynthesizer,
            text: *const c_char,
            style_id: VoicevoxStyleId,
            options: *const VoicevoxTtsOptions,
            wav_length: *mut uintptr_t,
            wav: *mut *mut c_uchar,
        ) -> c_int;

        // Metadata functions
        pub fn voicevox_synthesizer_create_metas_json(
            synthesizer: *mut VoicevoxSynthesizer,
        ) -> *mut c_char;

        // Model loading functions
        pub fn voicevox_synthesizer_load_voice_model(
            synthesizer: *const VoicevoxSynthesizer,
            model: *const VoicevoxVoiceModelFile,
        ) -> c_int;

        pub fn voicevox_voice_model_file_open(
            path: *const c_char,
            model: *mut *mut VoicevoxVoiceModelFile,
        ) -> c_int;

        pub fn voicevox_voice_model_file_delete(model: *mut VoicevoxVoiceModelFile);

        // Cleanup functions
        pub fn voicevox_wav_free(wav: *mut c_uchar);
        pub fn voicevox_json_free(json: *mut c_char);
        pub fn voicevox_synthesizer_delete(synthesizer: *mut VoicevoxSynthesizer);
        pub fn voicevox_open_jtalk_rc_delete(open_jtalk_rc: *mut OpenJtalkRc);
    }
}

#[cfg(not(feature = "use_bindgen"))]
use manual_bindings::*;

#[derive(Debug, Serialize, Deserialize)]
struct Speaker {
    name: String,
    #[serde(default)]
    speaker_uuid: String,
    styles: Vec<Style>,
    #[serde(default)]
    version: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct Style {
    name: String,
    id: u32,
    #[serde(rename = "type", skip_serializing_if = "Option::is_none")]
    style_type: Option<String>,
}

#[derive(Debug)]
struct VoicevoxCore {
    synthesizer: *mut VoicevoxSynthesizer,
    _open_jtalk_rc: *mut OpenJtalkRc,
}

unsafe impl Send for VoicevoxCore {}
unsafe impl Sync for VoicevoxCore {}

impl VoicevoxCore {
    fn new() -> Result<Self> {
        unsafe {
            // Load ONNX Runtime first
            let load_options = voicevox_make_default_load_onnxruntime_options();
            let mut onnxruntime: *const VoicevoxOnnxruntime = ptr::null();

            let result = voicevox_onnxruntime_load_once(load_options, &mut onnxruntime);
            if result != VOICEVOX_RESULT_OK {
                return Err(anyhow!(
                    "ONNX Runtime initialization failed: code {}",
                    result
                ));
            }

            // Initialize OpenJTalk
            let dict_path = find_openjtalk_dict()?;
            let dict_cstr = CString::new(dict_path)?;
            let mut open_jtalk_rc: *mut OpenJtalkRc = ptr::null_mut();

            let result = voicevox_open_jtalk_rc_new(dict_cstr.as_ptr(), &mut open_jtalk_rc);
            if result != VOICEVOX_RESULT_OK {
                return Err(anyhow!(
                    "OpenJTalk RC initialization failed: code {}",
                    result
                ));
            }

            // Create synthesizer with CPU-only mode for macOS
            #[cfg(target_os = "macos")]
            {
                println!("ğŸ–¥ï¸  Initializing VOICEVOX Core in CPU-only mode for macOS...");

                // Create CPU-only initialization options structure
                let init_options = VoicevoxInitializeOptions {
                    acceleration_mode: VoicevoxAccelerationMode::Cpu, // Force CPU mode, no GPU testing
                    cpu_num_threads: 0, // Use default number of CPU threads (0 = auto-detect)
                };

                let mut synthesizer: *mut VoicevoxSynthesizer = ptr::null_mut();
                let result = voicevox_synthesizer_new(
                    onnxruntime,
                    open_jtalk_rc,
                    init_options,
                    &mut synthesizer,
                );

                if result != VOICEVOX_RESULT_OK {
                    voicevox_open_jtalk_rc_delete(open_jtalk_rc);
                    return Err(anyhow!("Synthesizer creation failed: code {}", result));
                }

                println!("âœ… Initialization completed successfully");

                // Skip loading any default models - load only what's needed later
                // This makes startup much faster!

                Ok(VoicevoxCore {
                    synthesizer,
                    _open_jtalk_rc: open_jtalk_rc,
                })
            }

            // Fallback for non-macOS platforms - also use CPU-only mode
            #[cfg(not(target_os = "macos"))]
            {
                println!("ğŸ–¥ï¸  Initializing VOICEVOX Core in CPU-only mode...");

                // Create CPU-only initialization options structure
                let init_options = VoicevoxInitializeOptions {
                    acceleration_mode: VoicevoxAccelerationMode::Cpu, // Force CPU mode, no GPU testing
                    cpu_num_threads: 0, // Use default number of CPU threads (0 = auto-detect)
                };

                let mut synthesizer: *mut VoicevoxSynthesizer = ptr::null_mut();
                let result = voicevox_synthesizer_new(
                    onnxruntime,
                    open_jtalk_rc,
                    init_options,
                    &mut synthesizer,
                );

                if result != VOICEVOX_RESULT_OK {
                    voicevox_open_jtalk_rc_delete(open_jtalk_rc);
                    return Err(anyhow!("Synthesizer creation failed: code {}", result));
                }

                println!("âœ… Initialization completed successfully");

                // Do not load any models by default for fastest startup
                // Models will be loaded on demand based on the requested voice
                println!("ğŸš€ Core initialized - models will be loaded on demand");

                Ok(VoicevoxCore {
                    synthesizer,
                    _open_jtalk_rc: open_jtalk_rc,
                })
            }
        }
    }

    // Helper function to get the model number for a given voice/style ID

    fn load_default_models(synthesizer: *mut VoicevoxSynthesizer) -> Result<()> {
        // Load only essential models for faster startup
        // Priority: ãšã‚“ã ã‚‚ã‚“ (3.vvm), å››å›½ã‚ãŸã‚“ (2.vvm), æ˜¥æ—¥éƒ¨ã¤ã‚€ã (8.vvm)
        let default_models = ["3.vvm", "2.vvm", "8.vvm"];

        let models_dir = find_models_dir()?;

        println!("ğŸ“¦ Loading default VVM models for faster startup...");

        let mut loaded_count = 0;
        for model_name in &default_models {
            let model_path = models_dir.join(model_name);
            if model_path.exists() {
                if let Some(path_str) = model_path.to_str() {
                    if let Ok(path_cstr) = CString::new(path_str) {
                        unsafe {
                            let mut model: *mut VoicevoxVoiceModelFile = ptr::null_mut();
                            let result =
                                voicevox_voice_model_file_open(path_cstr.as_ptr(), &mut model);
                            if result == VOICEVOX_RESULT_OK {
                                let load_result =
                                    voicevox_synthesizer_load_voice_model(synthesizer, model);
                                if load_result == VOICEVOX_RESULT_OK {
                                    loaded_count += 1;
                                    println!("  âœ… Loaded: {}", model_name);
                                } else {
                                    println!(
                                        "  âš ï¸  Failed to load: {} (code: {})",
                                        model_name, load_result
                                    );
                                }
                                voicevox_voice_model_file_delete(model);
                            } else {
                                println!("  âš ï¸  Failed to open: {} (code: {})", model_name, result);
                            }
                        }
                    }
                }
            } else {
                println!("  âš ï¸  Model not found: {}", model_name);
            }
        }

        if loaded_count > 0 {
            println!("âœ… Successfully loaded {} default VVM models", loaded_count);
        } else {
            println!("âš ï¸  No default VVM models were loaded");
        }

        Ok(())
    }

    fn load_specific_model(&self, model_name: &str) -> Result<()> {
        let models_dir = find_models_dir()?;
        let model_path = models_dir.join(format!("{}.vvm", model_name));

        if !model_path.exists() {
            return Err(anyhow!("Model not found: {}.vvm", model_name));
        }

        println!("ğŸ“¦ Loading model: {}.vvm", model_name);

        if let Some(path_str) = model_path.to_str() {
            if let Ok(path_cstr) = CString::new(path_str) {
                unsafe {
                    let mut model: *mut VoicevoxVoiceModelFile = ptr::null_mut();
                    let result = voicevox_voice_model_file_open(path_cstr.as_ptr(), &mut model);
                    if result == VOICEVOX_RESULT_OK {
                        let load_result =
                            voicevox_synthesizer_load_voice_model(self.synthesizer, model);
                        if load_result == VOICEVOX_RESULT_OK {
                            println!("  âœ… Successfully loaded: {}.vvm", model_name);
                        } else if load_result == 18 {
                            // MODEL_ALREADY_LOADED_ERROR
                            // Model already loaded, this is OK
                            println!("  â„¹ï¸  Model {}.vvm already loaded", model_name);
                        } else {
                            voicevox_voice_model_file_delete(model);
                            return Err(anyhow!(
                                "Failed to load model: {} (code: {})",
                                model_name,
                                load_result
                            ));
                        }
                        voicevox_voice_model_file_delete(model);
                    } else {
                        return Err(anyhow!(
                            "Failed to open model: {} (code: {})",
                            model_name,
                            result
                        ));
                    }
                }
            }
        }
        Ok(())
    }

    fn load_models(synthesizer: *mut VoicevoxSynthesizer) -> Result<()> {
        // Find the models directory
        let models_dir = find_models_dir()?;

        println!("ğŸ“¦ Loading VVM models from: {}", models_dir.display());

        // Load all VVM files
        let mut loaded_count = 0;
        if let Ok(entries) = std::fs::read_dir(&models_dir) {
            for entry in entries.filter_map(|e| e.ok()) {
                if let Some(file_name) = entry.file_name().to_str() {
                    if file_name.ends_with(".vvm") {
                        let model_path = entry.path();
                        if let Some(path_str) = model_path.to_str() {
                            if let Ok(path_cstr) = CString::new(path_str) {
                                unsafe {
                                    // Try to load the model
                                    let mut model: *mut VoicevoxVoiceModelFile = ptr::null_mut();
                                    let result = voicevox_voice_model_file_open(
                                        path_cstr.as_ptr(),
                                        &mut model,
                                    );
                                    if result == VOICEVOX_RESULT_OK {
                                        let load_result = voicevox_synthesizer_load_voice_model(
                                            synthesizer,
                                            model,
                                        );
                                        if load_result == VOICEVOX_RESULT_OK {
                                            loaded_count += 1;
                                            println!("  âœ… Loaded: {}", file_name);
                                        } else {
                                            println!(
                                                "  âš ï¸  Failed to load: {} (code: {})",
                                                file_name, load_result
                                            );
                                        }
                                        voicevox_voice_model_file_delete(model);
                                    } else {
                                        println!(
                                            "  âš ï¸  Failed to open: {} (code: {})",
                                            file_name, result
                                        );
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        if loaded_count > 0 {
            println!("âœ… Successfully loaded {} VVM models", loaded_count);
        } else {
            println!("âš ï¸  No VVM models were loaded");
        }

        Ok(())
    }

    fn synthesize_simple(&self, text: &str, style_id: VoicevoxStyleId) -> Result<Vec<u8>> {
        unsafe {
            let text_cstr = CString::new(text)?;
            let tts_options = voicevox_make_default_tts_options();
            let mut wav_data: *mut u8 = ptr::null_mut();
            let mut wav_length: usize = 0;

            let result = voicevox_synthesizer_tts(
                self.synthesizer,
                text_cstr.as_ptr(),
                style_id,
                tts_options,
                &mut wav_length,
                &mut wav_data,
            );

            if result != VOICEVOX_RESULT_OK {
                return Err(anyhow!("Speech synthesis failed: code {}", result));
            }

            if wav_data.is_null() || wav_length == 0 {
                return Err(anyhow!("Audio data was not generated"));
            }

            let wav_vec = std::slice::from_raw_parts(wav_data, wav_length).to_vec();
            voicevox_wav_free(wav_data);
            Ok(wav_vec)
        }
    }

    fn synthesize_streaming(&self, text: &str, style_id: VoicevoxStyleId) -> Result<()> {
        self.synthesize_streaming_with_config(text, style_id, 100, None)
    }

    fn synthesize_streaming_with_config(
        &self,
        text: &str,
        style_id: VoicevoxStyleId,
        delay_ms: u64,
        chunk_size: Option<usize>,
    ) -> Result<()> {
        // ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªã‚µã‚¤ã‚ºã«åˆ†å‰²
        let sentences = if let Some(size) = chunk_size {
            split_text_by_size(text, size)
        } else {
            split_sentences(text)
        };

        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã‚·ãƒ³ã‚¯ã‚’åˆæœŸåŒ–
        let (_stream, stream_handle) = OutputStream::try_default()
            .map_err(|e| anyhow!("Failed to create audio stream: {}", e))?;
        let sink = Sink::try_new(&stream_handle)
            .map_err(|e| anyhow!("Failed to create audio sink: {}", e))?;

        println!(
            "ğŸµ Starting streaming synthesis for {} segments...",
            sentences.len()
        );
        if chunk_size.is_some() {
            println!(
                "   ğŸ“ Using character-based chunking (max {} chars per chunk)",
                chunk_size.unwrap()
            );
        } else {
            println!("   ï¿½ Using sentence-based chunking");
        }
        println!("   â±ï¸  Delay between segments: {}ms", delay_ms);

        let start_time = std::time::Instant::now();
        let mut total_synthesis_time = std::time::Duration::ZERO;

        // å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é †æ¬¡åˆæˆãƒ»å†ç”Ÿ
        for (i, segment) in sentences.iter().enumerate() {
            if segment.trim().is_empty() {
                continue;
            }

            let segment_display = if segment.len() > 30 {
                format!("{}...", &segment[..30])
            } else {
                segment.clone()
            };

            println!(
                "  ğŸ”Š [{}/{}] Processing: \"{}\"",
                i + 1,
                sentences.len(),
                segment_display
            );

            let synthesis_start = std::time::Instant::now();
            // éŸ³å£°åˆæˆ
            let wav_data = self.synthesize_simple(segment, style_id)?;
            let synthesis_time = synthesis_start.elapsed();
            total_synthesis_time += synthesis_time;

            // WAVãƒ‡ãƒ¼ã‚¿ã‚’éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã«å¤‰æ›
            let cursor = Cursor::new(wav_data);
            match Decoder::new(cursor) {
                Ok(source) => {
                    // éŸ³å£°ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ï¼ˆãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
                    sink.append(source);

                    println!("    âš¡ Synthesis: {:?}, Audio queued", synthesis_time);

                    // è¨­å®šã•ã‚ŒãŸé–“éš”ã§å¾…æ©Ÿ
                    if delay_ms > 0 {
                        std::thread::sleep(std::time::Duration::from_millis(delay_ms));
                    }
                }
                Err(e) => {
                    println!("  âš ï¸  Failed to decode audio for segment {}: {}", i + 1, e);
                }
            }
        }

        // å…¨ã¦ã®éŸ³å£°ãŒå†ç”Ÿã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
        println!("â³ Waiting for audio playback to complete...");
        sink.sleep_until_end();

        let total_time = start_time.elapsed();
        println!("âœ… Streaming synthesis completed!");
        println!(
            "   ğŸ“Š Total time: {:?}, Synthesis time: {:?}, Efficiency: {:.1}%",
            total_time,
            total_synthesis_time,
            (total_synthesis_time.as_secs_f64() / total_time.as_secs_f64()) * 100.0
        );
        Ok(())
    }

    fn get_speakers(&self) -> Result<Vec<Speaker>> {
        unsafe {
            let metas_json = voicevox_synthesizer_create_metas_json(self.synthesizer);
            if metas_json.is_null() {
                return Err(anyhow!("Failed to get speaker metadata"));
            }

            let metas_str = CStr::from_ptr(metas_json).to_str()?;
            let speakers: Vec<Speaker> = serde_json::from_str(metas_str)
                .map_err(|e| anyhow!("Failed to parse speaker metadata: {}", e))?;

            voicevox_json_free(metas_json);
            Ok(speakers)
        }
    }
}

impl Drop for VoicevoxCore {
    fn drop(&mut self) {
        unsafe {
            if !self.synthesizer.is_null() {
                voicevox_synthesizer_delete(self.synthesizer);
            }
            if !self._open_jtalk_rc.is_null() {
                voicevox_open_jtalk_rc_delete(self._open_jtalk_rc);
            }
        }
    }
}

// Helper function to find VVM models directory
fn find_models_dir() -> Result<PathBuf> {
    // Priority 1: Package installation path (when used as a Nix package)
    if let Ok(exe_path) = std::env::current_exe() {
        if let Some(pkg_root) = exe_path.parent().and_then(|p| p.parent()) {
            let pkg_models_path = pkg_root.join("share/voicevox/models");
            if pkg_models_path.exists() {
                return Ok(pkg_models_path);
            }
        }
    }

    // Priority 2: Development/workspace paths
    let workspace_root = std::env::current_dir()
        .ok()
        .and_then(|current_dir| {
            current_dir
                .ancestors()
                .find(|a| a.join("voicevox_models").exists())
                .map(|p| p.to_path_buf())
        })
        .unwrap_or_else(|| PathBuf::from("/Users/gen/Documents/usabarashi/mynix"));

    let models_dir = workspace_root.join("voicevox_models/models/vvms");
    if models_dir.exists() {
        Ok(models_dir)
    } else {
        // Priority 3: Environment variable (fallback)
        if let Ok(models_dir) = std::env::var("VOICEVOX_MODELS_DIR") {
            let models_path = PathBuf::from(&models_dir);
            if models_path.exists() {
                return Ok(models_path);
            }
        }
        Err(anyhow!("VVM models directory not found. Checked paths: package path, workspace path, environment VOICEVOX_MODELS_DIR"))
    }
}

// Helper function to check if a directory contains .dic files
fn has_dic_files(dict_path: &PathBuf) -> bool {
    if let Ok(entries) = std::fs::read_dir(dict_path) {
        entries.filter_map(|e| e.ok()).any(|e| {
            if let Some(file_name) = e.file_name().to_str() {
                file_name.ends_with(".dic")
            } else {
                false
            }
        })
    } else {
        false
    }
}

fn find_openjtalk_dict() -> Result<String> {
    // Priority 1: Package installation path (when used as a Nix package)
    if let Ok(exe_path) = std::env::current_exe() {
        if let Some(pkg_root) = exe_path.parent().and_then(|p| p.parent()) {
            let pkg_dict_path = pkg_root.join("share/voicevox/dict");
            if pkg_dict_path.exists() && has_dic_files(&pkg_dict_path) {
                let path_str = pkg_dict_path.to_string_lossy().to_string();
                println!("Found OpenJTalk dictionary (package): {}", path_str);
                return Ok(path_str);
            }
        }
    }

    // Priority 2: Development/workspace paths
    let workspace_root = std::env::current_dir()
        .ok()
        .and_then(|current_dir| {
            current_dir
                .ancestors()
                .find(|a| a.join("voicevox_models").exists())
                .map(|p| p.to_path_buf())
        })
        .unwrap_or_else(|| PathBuf::from("/Users/gen/Documents/usabarashi/mynix"));

    let possible_dict_paths = vec![
        workspace_root
            .join("voicevox_models/dict/open_jtalk_dic_utf_8-1.11")
            .to_string_lossy()
            .to_string(),
        workspace_root
            .join("dict/open_jtalk_dic_utf_8-1.11")
            .to_string_lossy()
            .to_string(),
        // System fallback paths
        "/opt/homebrew/share/open-jtalk/dic".to_string(),
        "/usr/local/share/open-jtalk/dic".to_string(),
        "/opt/local/share/open-jtalk/dic".to_string(),
        "/usr/share/open-jtalk/dic".to_string(),
        "./dict".to_string(),
    ];

    for path in &possible_dict_paths {
        let dict_path = PathBuf::from(path);
        if dict_path.exists() {
            // Check for .dic files
            if let Ok(entries) = std::fs::read_dir(&dict_path) {
                let has_dic_files = entries.filter_map(|e| e.ok()).any(|e| {
                    if let Some(file_name) = e.file_name().to_str() {
                        file_name.ends_with(".dic")
                    } else {
                        false
                    }
                });

                if has_dic_files {
                    println!("Found OpenJTalk dictionary: {}", path);
                    return Ok(path.to_string());
                }
            }
        }
    }

    // Priority 3: Environment variable (fallback)
    if let Ok(dict_dir) = std::env::var("VOICEVOX_DICT_DIR") {
        let dict_path = PathBuf::from(&dict_dir);
        if dict_path.exists() && has_dic_files(&dict_path) {
            println!("Found OpenJTalk dictionary (env fallback): {}", dict_dir);
            return Ok(dict_dir);
        }
    }

    Err(anyhow!(
        "OpenJTalk dictionary not found.\nChecked paths: {:?}",
        possible_dict_paths
    ))
}

// éŸ³å£°IDã‹ã‚‰å¿…è¦ãªVVMãƒ¢ãƒ‡ãƒ«ç•ªå·ã‚’å–å¾—
fn get_model_for_voice_id(voice_id: u32) -> Option<u32> {
    match voice_id {
        // ãšã‚“ã ã‚‚ã‚“ (3.vvm)
        1 | 3 | 7 => Some(3),
        // å››å›½ã‚ãŸã‚“ (2.vvm)
        2 | 0 | 6 | 4 => Some(2),
        // æ˜¥æ—¥éƒ¨ã¤ã‚€ã (8.vvm)
        8 | 83 | 84 => Some(8),
        // é›¨æ™´ã¯ã† (10.vvm)
        10 | 85 => Some(10),
        // æ³¢éŸ³ãƒªãƒ„ (9.vvm)
        9 | 65 => Some(9),
        // ç„é‡æ­¦å® (11.vvm)
        11 | 39 | 40 | 41 => Some(11),
        // ç™½ä¸Šè™å¤ªéƒ (12.vvm)
        12 | 32 | 33 => Some(12),
        // é’å±±é¾æ˜Ÿ (13.vvm)
        13 | 86 | 87 | 88 | 89 | 90 => Some(13),
        // å†¥é³´ã²ã¾ã‚Š (14.vvm)
        14 => Some(14),
        // ä¹å·ãã‚‰ (16.vvm)
        15 | 16 | 17 | 18 | 19 => Some(16),
        // ã‚‚ã¡å­ã•ã‚“ (17.vvm)
        20 => Some(17),
        // å‰£å´é›Œé›„ (18.vvm)
        21 => Some(18),
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸æ˜
        _ => None,
    }
}

// éŸ³å£°åã‹ã‚‰ã‚¹ã‚¿ã‚¤ãƒ«IDã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
fn get_voice_mapping() -> HashMap<&'static str, (u32, &'static str)> {
    let mut voices = HashMap::new();

    // ãšã‚“ã ã‚‚ã‚“ï¼ˆå…¨ãƒ¢ãƒ¼ãƒ‰ï¼‰
    voices.insert("zundamon", (3, "ãšã‚“ã ã‚‚ã‚“ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("zundamon-normal", (3, "ãšã‚“ã ã‚‚ã‚“ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("zundamon-amama", (1, "ãšã‚“ã ã‚‚ã‚“ (ã‚ã¾ã‚ã¾)"));
    voices.insert("zundamon-tsundere", (7, "ãšã‚“ã ã‚‚ã‚“ (ãƒ„ãƒ³ãƒ„ãƒ³)"));
    voices.insert("zundamon-sexy", (5, "ãšã‚“ã ã‚‚ã‚“ (ã‚»ã‚¯ã‚·ãƒ¼)"));
    voices.insert("zundamon-whisper", (22, "ãšã‚“ã ã‚‚ã‚“ (ã•ã•ã‚„ã)"));
    voices.insert("zundamon-excited", (38, "ãšã‚“ã ã‚‚ã‚“ (ãƒ˜ãƒ­ãƒ˜ãƒ­)"));

    // å››å›½ã‚ãŸã‚“ï¼ˆå…¨ãƒ¢ãƒ¼ãƒ‰ï¼‰
    voices.insert("metan", (2, "å››å›½ã‚ãŸã‚“ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("metan-normal", (2, "å››å›½ã‚ãŸã‚“ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("metan-amama", (0, "å››å›½ã‚ãŸã‚“ (ã‚ã¾ã‚ã¾)"));
    voices.insert("metan-tsundere", (6, "å››å›½ã‚ãŸã‚“ (ãƒ„ãƒ³ãƒ„ãƒ³)"));
    voices.insert("metan-sexy", (4, "å››å›½ã‚ãŸã‚“ (ã‚»ã‚¯ã‚·ãƒ¼)"));
    voices.insert("metan-whisper", (36, "å››å›½ã‚ãŸã‚“ (ã•ã•ã‚„ã)"));
    voices.insert("metan-excited", (37, "å››å›½ã‚ãŸã‚“ (ãƒ˜ãƒ­ãƒ˜ãƒ­)"));

    // æ˜¥æ—¥éƒ¨ã¤ã‚€ã
    voices.insert("tsumugi", (8, "æ˜¥æ—¥éƒ¨ã¤ã‚€ã (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("tsumugi-normal", (8, "æ˜¥æ—¥éƒ¨ã¤ã‚€ã (ãƒãƒ¼ãƒãƒ«)"));

    // é›¨æ™´ã¯ã†
    voices.insert("hau", (10, "é›¨æ™´ã¯ã† (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("hau-normal", (10, "é›¨æ™´ã¯ã† (ãƒãƒ¼ãƒãƒ«)"));

    // æ³¢éŸ³ãƒªãƒ„
    voices.insert("ritsu", (9, "æ³¢éŸ³ãƒªãƒ„ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("ritsu-normal", (9, "æ³¢éŸ³ãƒªãƒ„ (ãƒãƒ¼ãƒãƒ«)"));

    // ç„é‡æ­¦å®
    voices.insert("takehiro", (11, "ç„é‡æ­¦å® (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("takehiro-normal", (11, "ç„é‡æ­¦å® (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("takehiro-excited", (39, "ç„é‡æ­¦å® (å–œã³)"));
    voices.insert("takehiro-tsundere", (40, "ç„é‡æ­¦å® (ãƒ„ãƒ³ã‚®ãƒ¬)"));
    voices.insert("takehiro-sad", (41, "ç„é‡æ­¦å® (æ‚²ã—ã¿)"));

    // ç™½ä¸Šè™å¤ªéƒ
    voices.insert("kohtaro", (12, "ç™½ä¸Šè™å¤ªéƒ (ãµã¤ã†)"));
    voices.insert("kohtaro-normal", (12, "ç™½ä¸Šè™å¤ªéƒ (ãµã¤ã†)"));
    voices.insert("kohtaro-excited", (32, "ç™½ä¸Šè™å¤ªéƒ (ã‚ãƒ¼ã„)"));
    voices.insert("kohtaro-angry", (33, "ç™½ä¸Šè™å¤ªéƒ (ã³ãã³ã)"));

    // é’å±±é¾æ˜Ÿ
    voices.insert("ryusei", (13, "é’å±±é¾æ˜Ÿ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("ryusei-normal", (13, "é’å±±é¾æ˜Ÿ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("ryusei-excited", (86, "é’å±±é¾æ˜Ÿ (ç†±è¡€)"));
    voices.insert("ryusei-cool", (87, "é’å±±é¾æ˜Ÿ (ä¸æ©Ÿå«Œ)"));
    voices.insert("ryusei-sad", (88, "é’å±±é¾æ˜Ÿ (å–œã³)"));
    voices.insert("ryusei-surprised", (89, "é’å±±é¾æ˜Ÿ (ã—ã£ã¨ã‚Š)"));
    voices.insert("ryusei-whisper", (90, "é’å±±é¾æ˜Ÿ (ã‹ãªã—ã¿)"));

    // å†¥é³´ã²ã¾ã‚Š
    voices.insert("himari", (14, "å†¥é³´ã²ã¾ã‚Š (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("himari-normal", (14, "å†¥é³´ã²ã¾ã‚Š (ãƒãƒ¼ãƒãƒ«)"));

    // ä¹å·ãã‚‰
    voices.insert("sora", (16, "ä¹å·ãã‚‰ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("sora-normal", (16, "ä¹å·ãã‚‰ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("sora-amama", (15, "ä¹å·ãã‚‰ (ã‚ã¾ã‚ã¾)"));
    voices.insert("sora-tsundere", (18, "ä¹å·ãã‚‰ (ãƒ„ãƒ³ãƒ„ãƒ³)"));
    voices.insert("sora-sexy", (17, "ä¹å·ãã‚‰ (ã‚»ã‚¯ã‚·ãƒ¼)"));
    voices.insert("sora-whisper", (19, "ä¹å·ãã‚‰ (ã•ã•ã‚„ã)"));

    // ã‚‚ã¡å­ã•ã‚“
    voices.insert("mochiko", (20, "ã‚‚ã¡å­ã•ã‚“ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("mochiko-normal", (20, "ã‚‚ã¡å­ã•ã‚“ (ãƒãƒ¼ãƒãƒ«)"));

    // å‰£å´é›Œé›„
    voices.insert("menou", (21, "å‰£å´é›Œé›„ (ãƒãƒ¼ãƒãƒ«)"));
    voices.insert("menou-normal", (21, "å‰£å´é›Œé›„ (ãƒãƒ¼ãƒãƒ«)"));

    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ã‚¤ãƒªã‚¢ã‚¹
    voices.insert("default", (3, "ãšã‚“ã ã‚‚ã‚“ (ãƒãƒ¼ãƒãƒ«)"));

    voices
}

fn resolve_voice_name_with_core(voice_name: &str, core: &VoicevoxCore) -> Result<(u32, String)> {
    let voices = get_voice_mapping();

    // éŸ³å£°ä¸€è¦§è¡¨ç¤ºã®ç‰¹åˆ¥ãªã‚±ãƒ¼ã‚¹
    if voice_name == "?" {
        println!("ğŸ­ Available VOICEVOX voices:");
        println!();

        // ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è¡¨ç¤º
        println!("  ğŸ“ ãšã‚“ã ã‚‚ã‚“:");
        println!("    zundamon, zundamon-normal    (ID: 3)  - ãšã‚“ã ã‚‚ã‚“ (ãƒãƒ¼ãƒãƒ«)");
        println!("    zundamon-amama              (ID: 1)  - ãšã‚“ã ã‚‚ã‚“ (ã‚ã¾ã‚ã¾)");
        println!("    zundamon-tsundere           (ID: 7)  - ãšã‚“ã ã‚‚ã‚“ (ãƒ„ãƒ³ãƒ„ãƒ³)");
        println!("    zundamon-sexy               (ID: 5)  - ãšã‚“ã ã‚‚ã‚“ (ã‚»ã‚¯ã‚·ãƒ¼)");
        println!("    zundamon-whisper            (ID: 22) - ãšã‚“ã ã‚‚ã‚“ (ã•ã•ã‚„ã)");
        println!("    zundamon-excited            (ID: 38) - ãšã‚“ã ã‚‚ã‚“ (ãƒ˜ãƒ­ãƒ˜ãƒ­)");
        println!();

        println!("  ğŸŠ å››å›½ã‚ãŸã‚“:");
        println!("    metan, metan-normal         (ID: 2)  - å››å›½ã‚ãŸã‚“ (ãƒãƒ¼ãƒãƒ«)");
        println!("    metan-amama                 (ID: 0)  - å››å›½ã‚ãŸã‚“ (ã‚ã¾ã‚ã¾)");
        println!("    metan-tsundere              (ID: 6)  - å››å›½ã‚ãŸã‚“ (ãƒ„ãƒ³ãƒ„ãƒ³)");
        println!("    metan-sexy                  (ID: 4)  - å››å›½ã‚ãŸã‚“ (ã‚»ã‚¯ã‚·ãƒ¼)");
        println!("    metan-whisper               (ID: 36) - å››å›½ã‚ãŸã‚“ (ã•ã•ã‚„ã)");
        println!("    metan-excited               (ID: 37) - å››å›½ã‚ãŸã‚“ (ãƒ˜ãƒ­ãƒ˜ãƒ­)");
        println!();

        println!("  ğŸŒ¸ ãã®ä»–ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:");
        println!("    tsumugi                     (ID: 8)  - æ˜¥æ—¥éƒ¨ã¤ã‚€ã (ãƒãƒ¼ãƒãƒ«)");
        println!("    hau                         (ID: 10) - é›¨æ™´ã¯ã† (ãƒãƒ¼ãƒãƒ«)");
        println!("    ritsu                       (ID: 9)  - æ³¢éŸ³ãƒªãƒ„ (ãƒãƒ¼ãƒãƒ«)");
        println!("    takehiro                    (ID: 11) - ç„é‡æ­¦å® (ãƒãƒ¼ãƒãƒ«)");
        println!("    kohtaro                     (ID: 12) - ç™½ä¸Šè™å¤ªéƒ (ãµã¤ã†)");
        println!("    ryusei                      (ID: 13) - é’å±±é¾æ˜Ÿ (ãƒãƒ¼ãƒãƒ«)");
        println!("    sora                        (ID: 16) - ä¹å·ãã‚‰ (ãƒãƒ¼ãƒãƒ«)");
        println!();

        println!("Usage: voicevox-say --voice <voice_name> \"your text\"");
        println!("Example: voicevox-say --voice zundamon \"ã“ã‚“ã«ã¡ã¯\"");
        println!();
        println!("ğŸ’¡ Tip: Use --load-all-models to preload all voice models for faster synthesis.");
        println!("ğŸ’¡ Tip: Default models (zundamon, metan, tsumugi) are loaded automatically.");

        std::process::exit(0);
    }

    // ç›´æ¥ä¸€è‡´ã™ã‚‹ãƒœã‚¤ã‚¹åã‚’æ¢ã™
    if let Some(&(style_id, description)) = voices.get(voice_name) {
        return Ok((style_id, description.to_string()));
    }

    // æ•°å€¤ã¨ã—ã¦è§£æã‚’è©¦ã¿ã‚‹
    if let Ok(style_id) = voice_name.parse::<u32>() {
        return Ok((style_id, format!("Style ID {}", style_id)));
    }

    Err(anyhow!(
        "Unknown voice: {}. Use --voice ? to list available voices.",
        voice_name
    ))
}

fn resolve_voice_name(voice_name: &str) -> Result<(u32, String)> {
    let voices = get_voice_mapping();

    // éŸ³å£°ä¸€è¦§è¡¨ç¤ºã®ç‰¹åˆ¥ãªã‚±ãƒ¼ã‚¹
    if voice_name == "?" {
        println!("ğŸ­ Available VOICEVOX voices:");
        println!();

        // ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è¡¨ç¤º
        println!("  ğŸ“ ãšã‚“ã ã‚‚ã‚“:");
        println!("    zundamon, zundamon-normal    (ID: 3)  - ãšã‚“ã ã‚‚ã‚“ (ãƒãƒ¼ãƒãƒ«)");
        println!("    zundamon-amama              (ID: 1)  - ãšã‚“ã ã‚‚ã‚“ (ã‚ã¾ã‚ã¾)");
        println!("    zundamon-tsundere           (ID: 7)  - ãšã‚“ã ã‚‚ã‚“ (ãƒ„ãƒ³ãƒ„ãƒ³)");
        println!("    zundamon-sexy               (ID: 5)  - ãšã‚“ã ã‚‚ã‚“ (ã‚»ã‚¯ã‚·ãƒ¼)");
        println!("    zundamon-whisper            (ID: 22) - ãšã‚“ã ã‚‚ã‚“ (ã•ã•ã‚„ã)");
        println!("    zundamon-excited            (ID: 38) - ãšã‚“ã ã‚‚ã‚“ (ãƒ˜ãƒ­ãƒ˜ãƒ­)");
        println!();

        println!("  ğŸŠ å››å›½ã‚ãŸã‚“:");
        println!("    metan, metan-normal         (ID: 2)  - å››å›½ã‚ãŸã‚“ (ãƒãƒ¼ãƒãƒ«)");
        println!("    metan-amama                 (ID: 0)  - å››å›½ã‚ãŸã‚“ (ã‚ã¾ã‚ã¾)");
        println!("    metan-tsundere              (ID: 6)  - å››å›½ã‚ãŸã‚“ (ãƒ„ãƒ³ãƒ„ãƒ³)");
        println!("    metan-sexy                  (ID: 4)  - å››å›½ã‚ãŸã‚“ (ã‚»ã‚¯ã‚·ãƒ¼)");
        println!("    metan-whisper               (ID: 36) - å››å›½ã‚ãŸã‚“ (ã•ã•ã‚„ã)");
        println!("    metan-excited               (ID: 37) - å››å›½ã‚ãŸã‚“ (ãƒ˜ãƒ­ãƒ˜ãƒ­)");
        println!();

        println!("  ğŸŒ¸ ãã®ä»–ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:");
        println!("    tsumugi                     (ID: 8)  - æ˜¥æ—¥éƒ¨ã¤ã‚€ã (ãƒãƒ¼ãƒãƒ«)");
        println!("    hau                         (ID: 10) - é›¨æ™´ã¯ã† (ãƒãƒ¼ãƒãƒ«)");
        println!("    ritsu                       (ID: 9)  - æ³¢éŸ³ãƒªãƒ„ (ãƒãƒ¼ãƒãƒ«)");
        println!("    takehiro                    (ID: 11) - ç„é‡æ­¦å® (ãƒãƒ¼ãƒãƒ«)");
        println!("    kohtaro                     (ID: 12) - ç™½ä¸Šè™å¤ªéƒ (ãµã¤ã†)");
        println!("    ryusei                      (ID: 13) - é’å±±é¾æ˜Ÿ (ãƒãƒ¼ãƒãƒ«)");
        println!("    sora                        (ID: 16) - ä¹å·ãã‚‰ (ãƒãƒ¼ãƒãƒ«)");
        println!();

        println!("  ğŸ’¡ Tips:");
        println!("    - æ•°å€¤IDã‚’ç›´æ¥æŒ‡å®šã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™: -v 3");
        println!("    - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã®ã¿ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨: -v zundamon");
        println!("    - ç‰¹å®šã®ãƒ¢ãƒ¼ãƒ‰ã‚’æŒ‡å®š: -v zundamon-amama");
        println!();

        std::process::exit(0);
    }

    // ç›´æ¥çš„ãªæ•°å€¤æŒ‡å®šã‚’ã‚µãƒãƒ¼ãƒˆ
    if let Ok(style_id) = voice_name.parse::<u32>() {
        return Ok((style_id, format!("Style ID {}", style_id)));
    }

    // éŸ³å£°åã‹ã‚‰æ¤œç´¢
    if let Some((style_id, description)) = voices.get(voice_name) {
        Ok((*style_id, description.to_string()))
    } else {
        Err(anyhow!(
            "Unknown voice: '{}'. Use -v ? to list available voices.",
            voice_name
        ))
    }
}

// ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’å–å¾—ã™ã‚‹é–¢æ•°
fn get_input_text(matches: &clap::ArgMatches) -> Result<String> {
    // ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰
    if let Some(text) = matches.get_one::<String>("text") {
        return Ok(text.clone());
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰
    if let Some(file_path) = matches.get_one::<String>("input-file") {
        if file_path == "-" {
            // æ¨™æº–å…¥åŠ›ã‹ã‚‰èª­ã¿å–ã‚Š
            use std::io::{self, Read};
            let mut buffer = String::new();
            io::stdin().read_to_string(&mut buffer)?;
            return Ok(buffer.trim().to_string());
        } else {
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿å–ã‚Š
            return Ok(fs::read_to_string(file_path)?);
        }
    }

    // ãƒ†ã‚­ã‚¹ãƒˆãŒä½•ã‚‚æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯æ¨™æº–å…¥åŠ›ã‹ã‚‰
    use std::io::{self, Read};
    let mut buffer = String::new();
    io::stdin().read_to_string(&mut buffer)?;
    Ok(buffer.trim().to_string())
}

// ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼šãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡ã«åˆ†å‰²
fn split_sentences(text: &str) -> Vec<String> {
    let mut sentences = Vec::new();
    let mut current_sentence = String::new();

    for ch in text.chars() {
        current_sentence.push(ch);

        // æ–‡ã®çµ‚ç«¯æ–‡å­—ã‚’æ¤œå‡º
        if ch == 'ã€‚' || ch == 'ï¼' || ch == 'ï¼Ÿ' || ch == '.' || ch == '!' || ch == '?' {
            if !current_sentence.trim().is_empty() {
                sentences.push(current_sentence.trim().to_string());
                current_sentence.clear();
            }
        }
    }

    // æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°è¿½åŠ 
    if !current_sentence.trim().is_empty() {
        sentences.push(current_sentence.trim().to_string());
    }

    // ç©ºã®æ–‡ã‚’é™¤å¤–
    sentences
        .into_iter()
        .filter(|s| !s.trim().is_empty())
        .collect()
}

// ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼šãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šã—ãŸæ–‡å­—æ•°ã§åˆ†å‰²
fn split_text_by_size(text: &str, max_size: usize) -> Vec<String> {
    let mut chunks = Vec::new();
    let mut current_chunk = String::new();

    for word in text.split_whitespace() {
        if current_chunk.len() + word.len() + 1 > max_size && !current_chunk.is_empty() {
            chunks.push(current_chunk.trim().to_string());
            current_chunk.clear();
        }

        if !current_chunk.is_empty() {
            current_chunk.push(' ');
        }
        current_chunk.push_str(word);
    }

    if !current_chunk.trim().is_empty() {
        chunks.push(current_chunk.trim().to_string());
    }

    chunks
}

fn main() -> Result<()> {
    let app = Command::new("voicevox-say")
        .version(env!("CARGO_PKG_VERSION"))
        .about("ğŸ«› VOICEVOX Say - Convert text to audible speech using VOICEVOX")
        .arg(
            Arg::new("text")
                .help("Specify the text to speak on the command line")
                .index(1)
                .required(false),
        )
        .arg(
            Arg::new("voice")
                .help("Specify the voice to be used. Use '?' to list all available voices")
                .long("voice")
                .short('v')
                .value_name("VOICE")
                .default_value("zundamon"),
        )
        .arg(
            Arg::new("rate")
                .help("Speech rate multiplier (0.5-2.0, default: 1.0)")
                .long("rate")
                .short('r')
                .value_name("RATE")
                .value_parser(clap::value_parser!(f32))
                .default_value("1.0"),
        )
        .arg(
            Arg::new("output-file")
                .help("Specify the path for an audio file to be written")
                .long("output-file")
                .short('o')
                .value_name("FILE"),
        )
        .arg(
            Arg::new("input-file")
                .help("Specify a file to be spoken. Use '-' for stdin")
                .long("input-file")
                .short('f')
                .value_name("FILE"),
        )
        .arg(
            Arg::new("streaming")
                .help("Enable streaming synthesis (sentence-by-sentence)")
                .long("streaming")
                .action(clap::ArgAction::SetTrue),
        )
        .arg(
            Arg::new("quiet")
                .help("Don't play audio, only save to file")
                .long("quiet")
                .short('q')
                .action(clap::ArgAction::SetTrue),
        )
        .arg(
            Arg::new("list-speakers")
                .help("List all available speakers and styles from loaded models")
                .long("list-speakers")
                .action(clap::ArgAction::SetTrue),
        )
        .arg(
            Arg::new("speaker-id")
                .help("Directly specify speaker style ID (advanced users)")
                .long("speaker-id")
                .short('s')
                .value_name("ID")
                .value_parser(clap::value_parser!(u32))
                .conflicts_with("voice"),
        )
        .arg(
            Arg::new("load-all-models")
                .help("Load all available VVM models (slower startup, all voices available)")
                .long("load-all-models")
                .action(clap::ArgAction::SetTrue),
        );

    let matches = app.get_matches();

    // éŸ³å£°ä¸€è¦§è¡¨ç¤ºã®å‡¦ç†ï¼ˆæ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼‰
    if let Some(voice_name) = matches.get_one::<String>("voice") {
        if voice_name == "?" {
            resolve_voice_name("?")?; // ã“ã‚Œã¯å†…éƒ¨ã§exit(0)ã™ã‚‹
        }
    }

    // Initialize VOICEVOX Core
    println!("ğŸš€ Initializing VOICEVOX Core...");
    let mut core = VoicevoxCore::new()?;

    // Load all models if requested
    if matches.get_flag("load-all-models") {
        println!("ğŸ“¦ Loading all VVM models (--load-all-models specified)...");
        if let Err(e) = VoicevoxCore::load_models(core.synthesizer) {
            println!("âš ï¸  Warning: Failed to load some models: {}", e);
        }
    }

    println!("âœ… VOICEVOX Core initialized successfully");

    // è©³ç´°ãªã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ä¸€è¦§è¡¨ç¤º
    if matches.get_flag("list-speakers") {
        println!("ğŸ“‹ All available speakers and styles from loaded models:");
        let speakers = core.get_speakers()?;
        for speaker in &speakers {
            println!("  ğŸ‘¤ {}", speaker.name);
            for style in &speaker.styles {
                println!("    ğŸ­ {} (ID: {})", style.name, style.id);
                if let Some(style_type) = &style.style_type {
                    println!("        Type: {}", style_type);
                }
            }
            println!();
        }
        return Ok(());
    }

    // ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’å–å¾—
    let text = get_input_text(&matches)?;
    if text.trim().is_empty() {
        return Err(anyhow!(
            "No text provided. Use command line argument, -f file, or pipe text to stdin."
        ));
    }

    // éŸ³å£°è¨­å®šã‚’è§£æ±ºï¼ˆspeaker-idãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã¡ã‚‰ã‚’å„ªå…ˆï¼‰
    let (style_id, voice_description) =
        if let Some(speaker_id) = matches.get_one::<u32>("speaker-id") {
            (*speaker_id, format!("Style ID {}", speaker_id))
        } else {
            let voice_name = matches.get_one::<String>("voice").unwrap();
            resolve_voice_name(voice_name)?
        };

    // è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    let use_streaming = matches.get_flag("streaming");
    let rate = *matches.get_one::<f32>("rate").unwrap_or(&1.0);

    // ãƒ¬ãƒ¼ãƒˆç¯„å›²ãƒã‚§ãƒƒã‚¯
    if rate < 0.5 || rate > 2.0 {
        return Err(anyhow!("Rate must be between 0.5 and 2.0, got: {}", rate));
    }

    println!("ğŸ­ Voice: {}", voice_description);
    if rate != 1.0 {
        println!("âš¡ Rate: {}x", rate);
    }

    // å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„ã«èª­ã¿è¾¼ã¿ï¼ˆåˆæˆç›´å‰ã«å®Ÿè¡Œï¼‰
    if !matches.get_flag("load-all-models") {
        if let Some(model_num) = get_model_for_voice_id(style_id) {
            println!(
                "ğŸ“¦ Loading required model for style ID {}: {}.vvm",
                style_id, model_num
            );
            if let Err(e) = core.load_specific_model(&model_num.to_string()) {
                return Err(anyhow!(
                    "Failed to load required model for style ID {}: {}",
                    style_id,
                    e
                ));
            }
        } else {
            return Err(anyhow!("Unknown voice model required for style ID {}. Please ensure the voice model is available.", style_id));
        }
    }

    // éŸ³å£°åˆæˆã®å®Ÿè¡Œ
    if use_streaming {
        println!("ğŸµ Starting streaming synthesis...");
        core.synthesize_streaming_with_config(&text, style_id, 100, None)?;
    } else {
        println!("ğŸ¤ Synthesizing speech...");
        let wav_data = core.synthesize_simple(&text, style_id)?;
        println!("âœ… Speech synthesis completed ({} bytes)", wav_data.len());

        // ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if let Some(output_file) = matches.get_one::<String>("output-file") {
            fs::write(output_file, &wav_data)?;
            println!("ğŸ’¾ Audio saved to: {}", output_file);
        }

        // éŸ³å£°å†ç”Ÿï¼ˆquietãƒ¢ãƒ¼ãƒ‰ã§ãªã„å ´åˆï¼‰
        if !matches.get_flag("quiet") && matches.get_one::<String>("output-file").is_none() {
            let temp_file = "/tmp/voicevox_say_temp.wav";
            fs::write(temp_file, &wav_data)?;

            // macOSæ¨™æº–ã®afplayã§å†ç”Ÿ
            if let Ok(_) = std::process::Command::new("afplay").arg(temp_file).output() {
                // æˆåŠŸæ™‚ã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„ï¼ˆsayã‚³ãƒãƒ³ãƒ‰ã¨åŒæ§˜ï¼‰
            } else if let Ok(_) = std::process::Command::new("play").arg(temp_file).output() {
                // soxã§ã®å†ç”Ÿã‚‚ã‚µã‚¤ãƒ¬ãƒ³ãƒˆ
            } else {
                eprintln!("Warning: No audio player found. Install sox or use -o to save file");
            }

            // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            let _ = fs::remove_file(temp_file);
        }
    }

    Ok(())
}
